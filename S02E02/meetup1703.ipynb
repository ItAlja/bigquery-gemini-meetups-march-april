{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7fc0848",
      "metadata": {
        "id": "f7fc0848"
      },
      "source": [
        "# generate assets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c9e55cb",
      "metadata": {
        "id": "5c9e55cb"
      },
      "source": [
        "\n",
        "\n",
        "```markdown\n",
        "# BigQuery & Gemini: Generating and Analyzing Multimodal Data\n",
        "\n",
        "This notebook demonstrates how to use Vertex AI's generative models to create a multimodal dataset, store it in Google Cloud Storage, and then analyze it using BigQuery and Gemini.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf2909",
      "metadata": {
        "id": "5bcf2909"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 1. Setup and Installation\n",
        "\n",
        "First, let's install the necessary Python libraries for interacting with Google Cloud services.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a7ed3e2",
      "metadata": {
        "id": "8a7ed3e2",
        "outputId": "a8e9cc3e-543a-4783-ff80-5744dfad730d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.40.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (26.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.78.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery google-cloud-texttospeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CHdRLqzP9kA",
        "outputId": "575fd421-473a-4047-f3e8-3eeeaa69504b"
      },
      "id": "3CHdRLqzP9kA",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.40.1)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /root/.local/lib/python3.12/site-packages (2.34.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (26.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-texttospeech) (1.78.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade google-cloud-aiplatform[generative_models]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txjuHtfxT5o5",
        "outputId": "3f67d19b-085e-4ed9-8dd1-319e5c838a31"
      },
      "id": "txjuHtfxT5o5",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform[generative_models] in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "\u001b[33mWARNING: google-cloud-aiplatform 1.139.0 does not provide the extra 'generative-models'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (26.0)\n",
            "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (3.40.1)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (0.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (1.78.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform[generative_models]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform[generative_models]) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (2.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform[generative_models]) (0.14.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform[generative_models]) (1.8.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[generative_models]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[generative_models]) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[generative_models]) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform[generative_models]) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d620d1c",
      "metadata": {
        "id": "1d620d1c"
      },
      "source": [
        "\n",
        "```markdown\n",
        "Next, please fill in your Google Cloud project details and other configuration values below.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6aa8092f",
      "metadata": {
        "id": "6aa8092f"
      },
      "outputs": [],
      "source": [
        "#easy test - to be deleted later\n",
        "import os\n",
        "\n",
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "# Your Google Cloud Storage bucket name\n",
        "GCS_BUCKET = \" meetupmarch\"\n",
        "# Your BigQuery dataset name\n",
        "# BIGQUERY_DATASET = \"your_bigquery_dataset\"\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication\n",
        "# --- AUTHENTICATE ---\n",
        "# Authenticate with Google Cloud. This is crucial for running in a Colab environment.\n",
        "# It will trigger a pop-up window to ask for your credentials and permissions.\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "7va3ErSQOKfg"
      },
      "id": "7va3ErSQOKfg",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION AND IMPORTS ---\n",
        "import os\n",
        "import json\n",
        "import vertexai\n",
        "\n",
        "# CORRECTED IMPORTS: Import each client library on its own line.\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from google.cloud import texttospeech\n",
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "from vertexai.preview.generative_models import GenerativeModel\n"
      ],
      "metadata": {
        "id": "wK-xAsbpRVPy"
      },
      "id": "wK-xAsbpRVPy",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "from IPython.display import Audio\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import requests"
      ],
      "metadata": {
        "id": "J98QoN1QieFO"
      },
      "id": "J98QoN1QieFO",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Your Google Cloud Storage bucket name (no 'gs://' prefix)\n",
        "GCS_BUCKET_NAME = \"meetupmarch\"\n",
        "\n",
        "# Derived names for our BigQuery resources\n",
        "DATASET_ID = \"generative_assets_dataset\"\n",
        "TABLE_ID = \"assets_metadata\"\n",
        "\n",
        "# --- INITIALIZE CLIENTS ---\n",
        "# Initialize Vertex AI SDK and other clients with your project details.\n",
        "# After authentication, these clients will have the necessary permissions.\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "tts_client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "print(f\"Project: {PROJECT_ID}, Location: {LOCATION}\")\n",
        "print(\"Vertex AI and other Google Cloud clients initialized successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsomYsDzDexf",
        "outputId": "f89bad5d-c257-4d9a-a002-98bbf3da897a"
      },
      "id": "PsomYsDzDexf",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project: geminienterprise-485114, Location: us-central1\n",
            "Vertex AI and other Google Cloud clients initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PREPARE GCS BUCKET AND BIGQUERY DATASET ---\n",
        "# This code will create the resources if they don't already exist.\n",
        "\n",
        "# GCS Bucket\n",
        "bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "if not bucket.exists():\n",
        "    bucket.create(location=LOCATION)\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' created.\")\n",
        "else:\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzEj1qPBE8hx",
        "outputId": "399f8385-79fb-491b-ce34-5ba9c19ce436"
      },
      "id": "EzEj1qPBE8hx",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bucket 'meetupmarch' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BigQuery Dataset\n",
        "dataset_ref = bq_client.dataset(DATASET_ID)\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{DATASET_ID}' already exists.\")\n",
        "except Exception:\n",
        "    bq_client.create_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{DATASET_ID}' created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jr6cCWAE-WR",
        "outputId": "a082bd45-308f-4ce6-d88a-a584366d1064"
      },
      "id": "-Jr6cCWAE-WR",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'generative_assets_dataset' created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A list to hold metadata for all generated assets\n",
        "all_metadata = []"
      ],
      "metadata": {
        "id": "t2X2M7ZmE_-U"
      },
      "id": "t2X2M7ZmE_-U",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9da5ecfd",
      "metadata": {
        "id": "9da5ecfd"
      },
      "source": [
        "```markdown\n",
        "## 2. Data Generation with Vertex AI\n",
        "\n",
        "Now, let's generate some multimodal data using different Vertex AI models.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8d28fb",
      "metadata": {
        "id": "7f8d28fb"
      },
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 1 image\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ff521e6",
      "metadata": {
        "id": "1ff521e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88aabbf7-bca2-423a-cfc6-62306c44862c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image generated and saved as generated_image.png\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.vision_models import ImageGenerationModel\n",
        "\n",
        "# TODO: Specify your project ID and location\n",
        "# vertexai.init(project=\"your-project-id\", location=\"your-location\")\n",
        "\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "\n",
        "image_prompt = \"a futuristic banana-shaped spaceship flying through a nebula\"\n",
        "\n",
        "response = image_model.generate_images(prompt=image_prompt)\n",
        "\n",
        "# The response is a list of Image objects.\n",
        "# Access the first image directly and save it.\n",
        "response[0].save(\"generated_image.png\")\n",
        "\n",
        "print(\"Image generated and saved as generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 10 images\n",
        "```"
      ],
      "metadata": {
        "id": "VB7xoriXARcN"
      },
      "id": "VB7xoriXARcN"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Starting Image Generation (Imagen 3) ---\")\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "local_image_dir = \"generated_images\"\n",
        "os.makedirs(local_image_dir, exist_ok=True)\n",
        "\n",
        "image_prompts = [\n",
        "    \"A state-of-the-art chemical manufacturing plant at sunset, with clean energy sources visible.\",\n",
        "    \"Macro shot of a new, sustainable consumer goods product made from plant-based materials.\",\n",
        "    \"A team of engineers in a modern factory reviewing data on a holographic display.\",\n",
        "    \"Futuristic robotic arms assembling a complex piece of machinery with precision.\",\n",
        "    \"A digital twin of a manufacturing facility, showing real-time operational data streams.\",\n",
        "    \"An aerial view of a smart warehouse with autonomous forklifts and delivery drones.\",\n",
        "    \"A scientist in a lab coat examining a beaker with a glowing liquid.\",\n",
        "    \"High-end cosmetic products arranged in a minimalist, elegant composition.\",\n",
        "    \"A cross-section of an advanced engine, showing intricate inner workings.\",\n",
        "    \"A beautiful landscape shot of a factory that blends seamlessly with nature.\",\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(image_prompts):\n",
        "    local_filename = f\"{local_image_dir}/image_{i}.png\"\n",
        "    gcs_blob_name = f\"images/image_{i}.png\"\n",
        "\n",
        "    print(f\"Generating image {i+1}/10 with prompt: '{prompt[:50]}...'\")\n",
        "    response = image_model.generate_images(prompt=prompt)\n",
        "    response[0].save(local_filename)\n",
        "\n",
        "    # Upload to GCS\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "\n",
        "    # Store metadata\n",
        "    all_metadata.append({\n",
        "        \"asset_id\": f\"image_{i}\",\n",
        "        \"asset_type\": \"image\",\n",
        "        \"prompt\": prompt,\n",
        "        \"gcs_uri\": gcs_uri,\n",
        "        \"model_used\": \"imagen-3.0-generate-002\"\n",
        "    })\n",
        "    print(f\"Image {i+1} saved and uploaded to {gcs_uri}\")\n",
        "\n",
        "print(\"--- Image Generation Complete ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScAeOjp0ANp2",
        "outputId": "568c5080-af8d-4d20-cd12-9e58f93fd646"
      },
      "id": "ScAeOjp0ANp2",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Image Generation (Imagen 3) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.12/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating image 1/10 with prompt: 'A state-of-the-art chemical manufacturing plant at...'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.12/site-packages/vertexai/vision_models/_vision_models.py:1437: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "/root/.local/lib/python3.12/site-packages/vertexai/vision_models/_vision_models.py:154: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 1 saved and uploaded to gs://meetupmarch/images/image_0.png\n",
            "Generating image 2/10 with prompt: 'Macro shot of a new, sustainable consumer goods pr...'\n",
            "Image 2 saved and uploaded to gs://meetupmarch/images/image_1.png\n",
            "Generating image 3/10 with prompt: 'A team of engineers in a modern factory reviewing ...'\n",
            "Image 3 saved and uploaded to gs://meetupmarch/images/image_2.png\n",
            "Generating image 4/10 with prompt: 'Futuristic robotic arms assembling a complex piece...'\n",
            "Image 4 saved and uploaded to gs://meetupmarch/images/image_3.png\n",
            "Generating image 5/10 with prompt: 'A digital twin of a manufacturing facility, showin...'\n",
            "Image 5 saved and uploaded to gs://meetupmarch/images/image_4.png\n",
            "Generating image 6/10 with prompt: 'An aerial view of a smart warehouse with autonomou...'\n",
            "Image 6 saved and uploaded to gs://meetupmarch/images/image_5.png\n",
            "Generating image 7/10 with prompt: 'A scientist in a lab coat examining a beaker with ...'\n",
            "Image 7 saved and uploaded to gs://meetupmarch/images/image_6.png\n",
            "Generating image 8/10 with prompt: 'High-end cosmetic products arranged in a minimalis...'\n",
            "Image 8 saved and uploaded to gs://meetupmarch/images/image_7.png\n",
            "Generating image 9/10 with prompt: 'A cross-section of an advanced engine, showing int...'\n",
            "Image 9 saved and uploaded to gs://meetupmarch/images/image_8.png\n",
            "Generating image 10/10 with prompt: 'A beautiful landscape shot of a factory that blend...'\n",
            "Image 10 saved and uploaded to gs://meetupmarch/images/image_9.png\n",
            "--- Image Generation Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff21461c",
      "metadata": {
        "id": "ff21461c"
      },
      "source": [
        "```markdown\n",
        "### 2.2 Generate Music with Lyria\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need these libraries for making direct HTTP requests and handling authentication.\n",
        "import requests\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- Helper Functions Exactly as in the Notebook ---\n",
        "\n",
        "def send_request_to_google_api(api_endpoint, data=None):\n",
        "    \"\"\"\n",
        "    Sends an HTTP request to a Google API endpoint.\n",
        "    \"\"\"\n",
        "    creds, project = google.auth.default()\n",
        "    auth_req = google.auth.transport.requests.Request()\n",
        "    creds.refresh(auth_req)\n",
        "    access_token = creds.token\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {access_token}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    response = requests.post(api_endpoint, headers=headers, json=data)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "def generate_music(api_endpoint, request: dict):\n",
        "    \"\"\"\n",
        "    Wraps the request and calls the API.\n",
        "    \"\"\"\n",
        "    req = {\"instances\": [request], \"parameters\": {}}\n",
        "    resp = send_request_to_google_api(api_endpoint, req)\n",
        "    return resp[\"predictions\"]\n",
        "\n",
        "# --- Define the Model URL ---\n",
        "music_model = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/lyria-002:predict\"\n",
        "local_music_dir = \"generated_music\"\n",
        "os.makedirs(local_music_dir, exist_ok=True)\n",
        "\n",
        "print(\"Setup complete. You can now run the cells below to generate each song individually.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks9fY9-vd32v",
        "outputId": "b6e3fcb6-3795-418b-e3b6-7ca6526375ab"
      },
      "id": "ks9fY9-vd32v",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. You can now run the cells below to generate each song individually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simple version - to be deleted\n",
        "try:\n",
        "    print(\"Generating Song 1...\")\n",
        "    # New, more descriptive prompt to avoid safety filters.\n",
        "    prompt = \"An uplifting and motivational corporate anthem for a quarterly results presentation, featuring bright piano, a steady electronic beat, and subtle synth pads.\"\n",
        "\n",
        "    predictions = generate_music(music_model, {\"prompt\": prompt, \"duration_secs\": 20})\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        with open(f\"{local_music_dir}/music_1.wav\", \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(\"SUCCESS: Song 1 saved as music_1.wav\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song 1: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52gYkFkwdqzS",
        "outputId": "f68b3d61-faf4-4d7c-c037-5ea4f918e51a"
      },
      "id": "52gYkFkwdqzS",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 1...\n",
            "SUCCESS: Song 1 saved as music_1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 1\n",
        "    prompt = \"An uplifting and motivational corporate anthem for a quarterly results presentation, featuring bright piano, a steady electronic beat, and subtle synth pads.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooP_Ht_Bl5tF",
        "outputId": "3f517798-3435-49ca-eaa7-e4028d3146ba"
      },
      "id": "ooP_Ht_Bl5tF",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 1 using the correct method...\n",
            "SUCCESS: Song 1 saved locally.\n",
            "SUCCESS: Song 1 uploaded to GCS.\n",
            "SUCCESS: Metadata for Song 1 stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 2\n",
        "    prompt = \"A minimal, ambient electronic track for a technology product showcase, calm and focused.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD3CQbVTiDQA",
        "outputId": "0f23e2ad-9306-4622-c1b4-f2a9db0c489e"
      },
      "id": "ZD3CQbVTiDQA",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 2 using the correct method...\n",
            "SUCCESS: Song 2 saved locally.\n",
            "SUCCESS: Song 2 uploaded to GCS.\n",
            "SUCCESS: Metadata for Song 2 stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 3\n",
        "    prompt = \"A powerful, driving industrial beat with synth elements, suggesting innovation and power.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPlc78sh9lq",
        "outputId": "f662c275-e38d-4f5f-c67a-af5e0f2d507f"
      },
      "id": "_YPlc78sh9lq",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 3 using the correct method...\n",
            "SUCCESS: Song 3 saved locally.\n",
            "SUCCESS: Song 3 uploaded to GCS.\n",
            "SUCCESS: Metadata for Song 3 stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "4d825725",
      "metadata": {
        "id": "4d825725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea5513a-d413-444f-8156-b6ff29fc4749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 4 using the correct method...\n",
            "SUCCESS: Song 4 saved locally.\n",
            "SUCCESS: Song 4 uploaded to GCS.\n",
            "SUCCESS: Metadata for Song 4 stored.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 4\n",
        "    prompt = \"An atmospheric and thoughtful soundscape for a documentary about sustainable manufacturing.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0790ea5",
      "metadata": {
        "id": "a0790ea5"
      },
      "source": [
        "```markdown\n",
        "### 2.3 Generate Speech with Gemini TTS\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52bee2e",
      "metadata": {
        "id": "d52bee2e"
      },
      "outputs": [],
      "source": [
        "# generate 1 file only test\n",
        "from google.cloud import texttospeech\n",
        "\n",
        "client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "synthesis_input = texttospeech.SynthesisInput(text=\"Hello, this is a test of the Gemini Text-to-Speech API.\")\n",
        "voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "with open(\"generated_speech.mp3\", \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "    print('Audio content written to file \"generated_speech.mp3\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import texttospeech\n",
        "import google.auth\n",
        "\n",
        "# --- THE DEFINITIVE FIX: SET THE ENVIRONMENT VARIABLE ---\n",
        "# This command forces the project ID for the entire session at the OS level.\n",
        "# This is the most powerful way to set the project and should override all other settings.\n",
        "print(f\"Setting environment variable GOOGLE_CLOUD_PROJECT to '{PROJECT_ID}'...\")\n",
        "os.environ['GOOGLE_CLOUD_PROJECT'] = PROJECT_ID\n",
        "# --- END FIX ---\n",
        "\n",
        "\n",
        "# We re-initialize the client one more time to be certain it picks up the new environment variable.\n",
        "print(\"Re-initializing Text-to-Speech client...\")\n",
        "tts_client = texttospeech.TextToSpeechClient()\n",
        "print(\"Client re-initialized.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Starting Speech Generation (Text-to-Speech) ---\")\n",
        "local_speech_dir = \"generated_speech\"\n",
        "os.makedirs(local_speech_dir, exist_ok=True)\n",
        "\n",
        "speech_texts = [\n",
        "    \"Quarterly production targets have been exceeded by fifteen percent.\",\n",
        "    \"Safety protocol update: All personnel must attend the mandatory briefing on Friday.\",\n",
        "    \"The new supply chain optimization model is now live across all regions.\",\n",
        "    \"Alert: Unscheduled maintenance is required for assembly line three.\",\n",
        "    \"Our commitment to sustainable manufacturing has reduced our carbon footprint by 20% year-over-year.\",\n",
        "    \"The next shareholder meeting will be held on July 25th to discuss Q2 earnings.\",\n",
        "    \"Innovation in materials science is key to developing our next generation of products.\",\n",
        "    \"Customer feedback indicates a 95% satisfaction rate with our new service portal.\",\n",
        "    \"We are projecting a 10% growth in the consumer goods sector for the upcoming fiscal year.\",\n",
        "    \"Emergency shutdown procedures for the chemical processing unit have been initiated. This is a drill.\",\n",
        "]\n",
        "\n",
        "for i, text in enumerate(speech_texts):\n",
        "    local_filename = f\"{local_speech_dir}/speech_{i}.mp3\"\n",
        "    gcs_blob_name = f\"speech/speech_{i}.mp3\"\n",
        "\n",
        "    print(f\"\\nGenerating speech {i+1}/10 for text: '{text[:50]}...'\")\n",
        "\n",
        "    try:\n",
        "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "        voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "        response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "        with open(local_filename, \"wb\") as out:\n",
        "            out.write(response.audio_content)\n",
        "        print(f\"SUCCESS: Speech {i+1} saved locally.\")\n",
        "\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        print(f\"SUCCESS: Speech {i+1} uploaded to GCS.\")\n",
        "\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"speech_{i}\",\n",
        "            \"asset_type\": \"speech\",\n",
        "            \"prompt\": text,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"google-text-to-speech\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for speech {i+1} stored.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR generating speech for prompt {i+1}: {e}\")\n",
        "        print(\"If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\")\n",
        "        print(\"Skipping this entry.\")\n",
        "\n",
        "print(\"\\n--- Speech Generation Complete ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amYxyL_JFZiQ",
        "outputId": "f582588e-b630-46cd-ed86-f65864e9b788"
      },
      "id": "amYxyL_JFZiQ",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting environment variable GOOGLE_CLOUD_PROJECT to 'geminienterprise-485114'...\n",
            "Re-initializing Text-to-Speech client...\n",
            "Client re-initialized.\n",
            "\n",
            "--- Starting Speech Generation (Text-to-Speech) ---\n",
            "\n",
            "Generating speech 1/10 for text: 'Quarterly production targets have been exceeded by...'\n",
            "ERROR generating speech for prompt 1: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 2/10 for text: 'Safety protocol update: All personnel must attend ...'\n",
            "ERROR generating speech for prompt 2: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 3/10 for text: 'The new supply chain optimization model is now liv...'\n",
            "ERROR generating speech for prompt 3: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 4/10 for text: 'Alert: Unscheduled maintenance is required for ass...'\n",
            "ERROR generating speech for prompt 4: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 5/10 for text: 'Our commitment to sustainable manufacturing has re...'\n",
            "ERROR generating speech for prompt 5: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 6/10 for text: 'The next shareholder meeting will be held on July ...'\n",
            "ERROR generating speech for prompt 6: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 7/10 for text: 'Innovation in materials science is key to developi...'\n",
            "ERROR generating speech for prompt 7: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 8/10 for text: 'Customer feedback indicates a 95% satisfaction rat...'\n",
            "ERROR generating speech for prompt 8: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 9/10 for text: 'We are projecting a 10% growth in the consumer goo...'\n",
            "ERROR generating speech for prompt 9: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "Generating speech 10/10 for text: 'Emergency shutdown procedures for the chemical pro...'\n",
            "ERROR generating speech for prompt 10: 403 Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry. [reason: \"SERVICE_DISABLED\"\n",
            "domain: \"googleapis.com\"\n",
            "metadata {\n",
            "  key: \"service\"\n",
            "  value: \"texttospeech.googleapis.com\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"serviceTitle\"\n",
            "  value: \"Cloud Text-to-Speech API\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"containerInfo\"\n",
            "  value: \"522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"consumer\"\n",
            "  value: \"projects/522309567947\"\n",
            "}\n",
            "metadata {\n",
            "  key: \"activationUrl\"\n",
            "  value: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            ", locale: \"en-US\"\n",
            "message: \"Cloud Text-to-Speech API has not been used in project 522309567947 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\"\n",
            ", links {\n",
            "  description: \"Google developers console API activation\"\n",
            "  url: \"https://console.developers.google.com/apis/api/texttospeech.googleapis.com/overview?project=522309567947\"\n",
            "}\n",
            "]\n",
            "If this error persists, the issue is with the notebook environment's core authentication and may require restarting the runtime or contacting support.\n",
            "Skipping this entry.\n",
            "\n",
            "--- Speech Generation Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1f6e5a",
      "metadata": {
        "id": "da1f6e5a"
      },
      "source": [
        "```markdown\n",
        "## 3. Upload to Google Cloud Storage\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bf9d1d",
      "metadata": {
        "id": "b5bf9d1d"
      },
      "outputs": [],
      "source": [
        "# easy version\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(GCS_BUCKET)\n",
        "\n",
        "def upload_to_gcs(filename):\n",
        "    blob = bucket.blob(filename)\n",
        "    blob.upload_from_filename(filename)\n",
        "    return f\"gs://{GCS_BUCKET}/{filename}\"\n",
        "\n",
        "image_gcs_uri = upload_to_gcs(\"generated_image.png\")\n",
        "music_gcs_uri = upload_to_gcs(\"generated_music_prompt.txt\")\n",
        "speech_gcs_uri = upload_to_gcs(\"generated_speech.mp3\")\n",
        "\n",
        "print(f\"Image URI: {image_gcs_uri}\")\n",
        "print(f\"Music URI: {music_gcs_uri}\")\n",
        "print(f\"Speech URI: {speech_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  BigQuery Metadata Ingestion"
      ],
      "metadata": {
        "id": "cR83nAMwIwyd"
      },
      "id": "cR83nAMwIwyd"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating and Uploading Metadata File ---\")\n",
        "local_metadata_filename = \"metadata.jsonl\"\n",
        "gcs_metadata_blob_name = \"metadata/assets.jsonl\"\n",
        "\n",
        "with open(local_metadata_filename, \"w\") as f:\n",
        "    for item in all_metadata:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "blob = bucket.blob(gcs_metadata_blob_name)\n",
        "blob.upload_from_filename(local_metadata_filename)\n",
        "metadata_gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_metadata_blob_name}\"\n",
        "\n",
        "print(f\"Metadata file uploaded to {metadata_gcs_uri}\")\n"
      ],
      "metadata": {
        "id": "bQsnvwy5Ivru"
      },
      "id": "bQsnvwy5Ivru",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create BigQuery External Table"
      ],
      "metadata": {
        "id": "Yr_jJVRiI3PD"
      },
      "id": "Yr_jJVRiI3PD"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating BigQuery External Table ---\")\n",
        "\n",
        "table_ref = dataset_ref.table(TABLE_ID)\n",
        "\n",
        "# Define the schema for the external table\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"asset_id\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"asset_type\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"prompt\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"model_used\", \"STRING\"),\n",
        "]\n",
        "\n",
        "external_config = bigquery.ExternalConfig(\"JSON\")\n",
        "external_config.source_uris = [metadata_gcs_uri]\n",
        "external_config.schema = schema\n",
        "# For JSONL, autodetect often works well, but explicit schema is safer.\n",
        "# external_config.autodetect = True\n",
        "\n",
        "# Create the table\n",
        "try:\n",
        "    bq_client.delete_table(table_ref, not_found_ok=True) # Delete if it exists to ensure a fresh start\n",
        "    print(f\"Existing table '{TABLE_ID}' deleted.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "table = bigquery.Table(table_ref)\n",
        "table.external_data_configuration = external_config\n",
        "table = bq_client.create_table(table)\n",
        "\n",
        "print(f\"External table '{table.project}.{table.dataset_id}.{table.table_id}' created successfully.\")\n"
      ],
      "metadata": {
        "id": "ymcPMZl4I4fO"
      },
      "id": "ymcPMZl4I4fO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Data with BigQuery and Gemini"
      ],
      "metadata": {
        "id": "wgzxSLbWI9SP"
      },
      "id": "wgzxSLbWI9SP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the SQL: You'll need a reference to a Gemini model in BigQuery. If you don't have one, you can create it with this DDL command in BigQuery:"
      ],
      "metadata": {
        "id": "IoAKj743JKlj"
      },
      "id": "IoAKj743JKlj"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating BigQuery Remote Model ---\")\n",
        "\n",
        "# --- CONFIGURATION for BigQuery Connection ---\n",
        "# !!! IMPORTANT !!!\n",
        "# Please replace this with the actual ID of your BigQuery connection.\n",
        "# The connection must be created in the same location as your dataset (e.g., 'us-central1').\n",
        "CONNECTION_NAME = \"your-bq-connection-to-vertex-ai\" # e.g., \"bq-vertex-connection\"\n",
        "\n",
        "# Define the SQL query to create the remote model\n",
        "sql_create_model = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_pro_vision_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "OPTIONS (remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "\"\"\"\n",
        "\n",
        "print(\"Executing query to create or replace BigQuery remote model...\")\n",
        "# Execute the query using the BigQuery client\n",
        "query_job = bq_client.query(sql_create_model)\n",
        "query_job.result()  # Wait for the job to complete\n",
        "\n",
        "print(f\"BigQuery remote model `{DATASET_ID}.gemini_pro_vision_model` created or replaced successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "F74OwcFbJFvj"
      },
      "id": "F74OwcFbJFvj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Analyzing Images with Gemini in BigQuery ---\")\n",
        "\n",
        "# The fully qualified ID of the table we created earlier\n",
        "full_table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "# This query selects only the image assets, then passes their GCS URI and\n",
        "# the original prompt to the Gemini model for analysis.\n",
        "sql_analyze = f\"\"\"\n",
        "SELECT\n",
        "    prompt,\n",
        "    gcs_uri,\n",
        "    ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "FROM\n",
        "    ML.GENERATE_TEXT(\n",
        "        MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_pro_vision_model`,\n",
        "        (\n",
        "            -- Subquery to select only the images and their URIs\n",
        "            SELECT\n",
        "                prompt,\n",
        "                gcs_uri\n",
        "            FROM\n",
        "                `{full_table_id}`\n",
        "            WHERE\n",
        "                asset_type = 'image'\n",
        "        ),\n",
        "        STRUCT(\n",
        "            -- This is the prompt for the LLM analysis itself\n",
        "            'Describe this image in detail based on its content. Also, comment on how well it matches the original user prompt.' AS prompt,\n",
        "            TRUE AS flatten_json_output\n",
        "        )\n",
        "    );\n",
        "\"\"\"\n",
        "\n",
        "print(\"Executing analysis query... This may take a few moments.\")\n",
        "# Execute the query and load the results into a pandas DataFrame\n",
        "df = bq_client.query(sql_analyze).to_dataframe()\n",
        "\n",
        "# Display the results in a clean markdown format\n",
        "print(\"\\n--- Gemini Vision Analysis Results ---\")\n",
        "print(df.to_markdown(index=False))\n"
      ],
      "metadata": {
        "id": "z6MOdArpI_iZ"
      },
      "id": "z6MOdArpI_iZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "94c153e8",
      "metadata": {
        "id": "94c153e8"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 4. Create BigQuery Table\n",
        "\n",
        "Now we'll create a JSONL file with metadata about our generated assets and upload it to GCS. Then we'll create a BigQuery external table that points to this metadata file.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3591f259",
      "metadata": {
        "id": "3591f259"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "metadata = [\n",
        "    {\"prompt\": image_prompt, \"gcs_uri\": image_gcs_uri, \"type\": \"image\"},\n",
        "    {\"prompt\": music_prompt, \"gcs_uri\": music_gcs_uri, \"type\": \"music\"},\n",
        "    {\"prompt\": \"Hello, this is a test of the Gemini Text-to-Speech API.\", \"gcs_uri\": speech_gcs_uri, \"type\": \"speech\"}\n",
        "]\n",
        "\n",
        "with open(\"metadata.jsonl\", \"w\") as f:\n",
        "    for item in metadata:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "metadata_gcs_uri = upload_to_gcs(\"metadata.jsonl\")\n",
        "print(f\"Metadata GCS URI: {metadata_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a54793",
      "metadata": {
        "id": "a0a54793"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "dataset_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}\"\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_id)  # Make an API request.\n",
        "    print(f\"Dataset {dataset_id} already exists.\")\n",
        "except Exception:\n",
        "    dataset = bigquery.Dataset(dataset_id)\n",
        "    dataset.location = LOCATION\n",
        "    dataset = bq_client.create_dataset(dataset, timeout=30)\n",
        "    print(f\"Created dataset {PROJECT_ID}.{dataset.dataset_id}\")\n",
        "\n",
        "table_id = f\"{dataset_id}.multimodal_assets\"\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"prompt\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"type\", \"STRING\"),\n",
        "]\n",
        "\n",
        "external_config = bigquery.ExternalConfig(\"NEWLINE_DELIMITED_JSON\")\n",
        "external_config.source_uris = [metadata_gcs_uri]\n",
        "external_config.schema = schema\n",
        "table = bigquery.Table(table_id, schema=schema)\n",
        "table.external_data_configuration = external_config\n",
        "table = bq_client.create_table(table, exists_ok=True)\n",
        "\n",
        "print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d99e7f3",
      "metadata": {
        "id": "4d99e7f3"
      },
      "source": [
        "```markdown\n",
        "## 5. Analyze Data with BigQuery and Gemini\n",
        "\n",
        "Finally, we'll create a remote model in BigQuery that points to the Gemini Pro Vision model. This will allow us to analyze the images directly from BigQuery using SQL.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2b05e1",
      "metadata": {
        "id": "2b2b05e1"
      },
      "outputs": [],
      "source": [
        "# This step assumes you have a BigQuery connection to Vertex AI set up.\n",
        "# See: https://cloud.google.com/bigquery/docs/create-cloud-resource-connection\n",
        "CONNECTION_NAME = \"your-bq-connection-to-vertex-ai\"\n",
        "\n",
        "sql_create_model = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "OPTIONS (remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(sql_create_model)\n",
        "query_job.result()  # Wait for the job to complete\n",
        "print(\"BigQuery remote model created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc30d9b",
      "metadata": {
        "id": "6dc30d9b"
      },
      "outputs": [],
      "source": [
        "sql_analyze = f\"\"\"\n",
        "SELECT\n",
        "    prompt,\n",
        "    gcs_uri,\n",
        "    ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "FROM\n",
        "    ML.GENERATE_TEXT(\n",
        "        MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`,\n",
        "        (SELECT prompt, gcs_uri FROM `{table_id}` WHERE type = 'image'),\n",
        "        STRUCT('Analyze the following image:' AS prompt, TRUE AS flatten_json_output)\n",
        "    );\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(sql_analyze).to_dataframe()\n",
        "print(df.to_markdown())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}