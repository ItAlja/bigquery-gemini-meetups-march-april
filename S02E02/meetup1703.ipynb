{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7fc0848",
      "metadata": {
        "id": "f7fc0848"
      },
      "source": [
        "# generate assets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c9e55cb",
      "metadata": {
        "id": "5c9e55cb"
      },
      "source": [
        "\n",
        "\n",
        "```markdown\n",
        "# BigQuery & Gemini: Generating and Analyzing Multimodal Data\n",
        "\n",
        "This notebook demonstrates how to use Vertex AI's generative models to create a multimodal dataset, store it in Google Cloud Storage, and then analyze it using BigQuery and Gemini.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf2909",
      "metadata": {
        "id": "5bcf2909"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 1. Setup and Installation\n",
        "\n",
        "First, let's install the necessary Python libraries for interacting with Google Cloud services.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7ed3e2",
      "metadata": {
        "id": "8a7ed3e2",
        "outputId": "a8e9cc3e-543a-4783-ff80-5744dfad730d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.40.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (26.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.78.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery google-cloud-texttospeech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CHdRLqzP9kA",
        "outputId": "575fd421-473a-4047-f3e8-3eeeaa69504b"
      },
      "id": "3CHdRLqzP9kA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.40.1)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /root/.local/lib/python3.12/site-packages (2.34.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (26.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-texttospeech) (1.78.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade google-cloud-aiplatform[generative_models]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txjuHtfxT5o5",
        "outputId": "3f67d19b-085e-4ed9-8dd1-319e5c838a31"
      },
      "id": "txjuHtfxT5o5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform[generative_models] in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "\u001b[33mWARNING: google-cloud-aiplatform 1.139.0 does not provide the extra 'generative-models'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (26.0)\n",
            "Requirement already satisfied: google-cloud-storage<4.0.0,>=1.32.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (3.40.1)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform[generative_models]) (0.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (2.32.4)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (1.78.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform[generative_models]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform[generative_models]) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (2.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform[generative_models]) (0.14.3)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage<4.0.0,>=1.32.0->google-cloud-aiplatform[generative_models]) (1.8.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[generative_models]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[generative_models]) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform[generative_models]) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform[generative_models]) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform[generative_models]) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform[generative_models]) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform[generative_models]) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d620d1c",
      "metadata": {
        "id": "1d620d1c"
      },
      "source": [
        "\n",
        "```markdown\n",
        "Next, please fill in your Google Cloud project details and other configuration values below.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "6aa8092f",
      "metadata": {
        "id": "6aa8092f"
      },
      "outputs": [],
      "source": [
        "#easy test - to be deleted later\n",
        "import os\n",
        "\n",
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "# Your Google Cloud Storage bucket name\n",
        "GCS_BUCKET = \" meetupmarch\"\n",
        "# Your BigQuery dataset name\n",
        "# BIGQUERY_DATASET = \"your_bigquery_dataset\"\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication\n",
        "# --- AUTHENTICATE ---\n",
        "# Authenticate with Google Cloud. This is crucial for running in a Colab environment.\n",
        "# It will trigger a pop-up window to ask for your credentials and permissions.\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "7va3ErSQOKfg"
      },
      "id": "7va3ErSQOKfg",
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION AND IMPORTS ---\n",
        "import os\n",
        "import json\n",
        "import vertexai\n",
        "\n",
        "# CORRECTED IMPORTS: Import each client library on its own line.\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from google.cloud import texttospeech\n",
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "from vertexai.preview.generative_models import GenerativeModel\n"
      ],
      "metadata": {
        "id": "wK-xAsbpRVPy"
      },
      "id": "wK-xAsbpRVPy",
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "\n",
        "from IPython.display import Audio\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import requests"
      ],
      "metadata": {
        "id": "J98QoN1QieFO"
      },
      "id": "J98QoN1QieFO",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Your Google Cloud Storage bucket name (no 'gs://' prefix)\n",
        "GCS_BUCKET_NAME = \"meetupmarch\"\n",
        "\n",
        "# Derived names for our BigQuery resources\n",
        "DATASET_ID = \"generative_assets_dataset\"\n",
        "TABLE_ID = \"assets_metadata\"\n",
        "\n",
        "# --- INITIALIZE CLIENTS ---\n",
        "# Initialize Vertex AI SDK and other clients with your project details.\n",
        "# After authentication, these clients will have the necessary permissions.\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "tts_client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "print(f\"Project: {PROJECT_ID}, Location: {LOCATION}\")\n",
        "print(\"Vertex AI and other Google Cloud clients initialized successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsomYsDzDexf",
        "outputId": "1f41e412-a709-4bd7-cce5-a1d60c22c98c"
      },
      "id": "PsomYsDzDexf",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project: geminienterprise-485114, Location: us-central1\n",
            "Vertex AI and other Google Cloud clients initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PREPARE GCS BUCKET AND BIGQUERY DATASET ---\n",
        "# This code will create the resources if they don't already exist.\n",
        "\n",
        "# GCS Bucket\n",
        "bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "if not bucket.exists():\n",
        "    bucket.create(location=LOCATION)\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' created.\")\n",
        "else:\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' already exists.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzEj1qPBE8hx",
        "outputId": "67933b6c-90b7-456f-fcfd-fee3b290a518"
      },
      "id": "EzEj1qPBE8hx",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bucket 'meetupmarch' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BigQuery Dataset\n",
        "dataset_ref = bq_client.dataset(DATASET_ID)\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{DATASET_ID}' already exists.\")\n",
        "except Exception:\n",
        "    bq_client.create_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{DATASET_ID}' created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jr6cCWAE-WR",
        "outputId": "766c02fc-984e-49a3-c030-1cca9b58abe7"
      },
      "id": "-Jr6cCWAE-WR",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'generative_assets_dataset' already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A list to hold metadata for all generated assets\n",
        "all_metadata = []"
      ],
      "metadata": {
        "id": "t2X2M7ZmE_-U"
      },
      "id": "t2X2M7ZmE_-U",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9da5ecfd",
      "metadata": {
        "id": "9da5ecfd"
      },
      "source": [
        "```markdown\n",
        "## 2. Data Generation with Vertex AI\n",
        "\n",
        "Now, let's generate some multimodal data using different Vertex AI models.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8d28fb",
      "metadata": {
        "id": "7f8d28fb"
      },
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 1 image\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "1ff521e6",
      "metadata": {
        "id": "1ff521e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e76bc47-80b4-4754-8f2d-424f123a1137"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/lib/python3.12/site-packages/vertexai/_model_garden/_model_garden_models.py:278: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "/root/.local/lib/python3.12/site-packages/vertexai/vision_models/_vision_models.py:1437: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n",
            "/root/.local/lib/python3.12/site-packages/vertexai/vision_models/_vision_models.py:154: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image generated and saved as generated_image.png\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.vision_models import ImageGenerationModel\n",
        "\n",
        "# TODO: Specify your project ID and location\n",
        "# vertexai.init(project=\"your-project-id\", location=\"your-location\")\n",
        "\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "\n",
        "image_prompt = \"a futuristic banana-shaped spaceship flying through a nebula\"\n",
        "\n",
        "response = image_model.generate_images(prompt=image_prompt)\n",
        "\n",
        "# The response is a list of Image objects.\n",
        "# Access the first image directly and save it.\n",
        "response[0].save(\"generated_image.png\")\n",
        "\n",
        "print(\"Image generated and saved as generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 10 images\n",
        "```"
      ],
      "metadata": {
        "id": "VB7xoriXARcN"
      },
      "id": "VB7xoriXARcN"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Starting Image Generation (Imagen 3) ---\")\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "local_image_dir = \"generated_images\"\n",
        "os.makedirs(local_image_dir, exist_ok=True)\n",
        "\n",
        "image_prompts = [\n",
        "    \"A state-of-the-art chemical manufacturing plant at sunset, with clean energy sources visible.\",\n",
        "    \"Macro shot of a new, sustainable consumer goods product made from plant-based materials.\",\n",
        "    \"A team of engineers in a modern factory reviewing data on a holographic display.\",\n",
        "    \"Futuristic robotic arms assembling a complex piece of machinery with precision.\",\n",
        "    \"A digital twin of a manufacturing facility, showing real-time operational data streams.\",\n",
        "    \"An aerial view of a smart warehouse with autonomous forklifts and delivery drones.\",\n",
        "    \"A scientist in a lab coat examining a beaker with a glowing liquid.\",\n",
        "    \"High-end cosmetic products arranged in a minimalist, elegant composition.\",\n",
        "    \"A cross-section of an advanced engine, showing intricate inner workings.\",\n",
        "    \"A beautiful landscape shot of a factory that blends seamlessly with nature.\",\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(image_prompts):\n",
        "    local_filename = f\"{local_image_dir}/image_{i}.png\"\n",
        "    gcs_blob_name = f\"images/image_{i}.png\"\n",
        "\n",
        "    print(f\"Generating image {i+1}/10 with prompt: '{prompt[:50]}...'\")\n",
        "    response = image_model.generate_images(prompt=prompt)\n",
        "    response[0].save(local_filename)\n",
        "\n",
        "    # Upload to GCS\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "\n",
        "    # Store metadata\n",
        "    all_metadata.append({\n",
        "        \"asset_id\": f\"image_{i}\",\n",
        "        \"asset_type\": \"image\",\n",
        "        \"prompt\": prompt,\n",
        "        \"gcs_uri\": gcs_uri,\n",
        "        \"model_used\": \"imagen-3.0-generate-002\"\n",
        "    })\n",
        "    print(f\"Image {i+1} saved and uploaded to {gcs_uri}\")\n",
        "\n",
        "print(\"--- Image Generation Complete ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScAeOjp0ANp2",
        "outputId": "f0f8c375-6ed1-4dfb-d3df-04005851edc3"
      },
      "id": "ScAeOjp0ANp2",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Image Generation (Imagen 3) ---\n",
            "Generating image 1/10 with prompt: 'A state-of-the-art chemical manufacturing plant at...'\n",
            "Image 1 saved and uploaded to gs://meetupmarch/images/image_0.png\n",
            "Generating image 2/10 with prompt: 'Macro shot of a new, sustainable consumer goods pr...'\n",
            "Image 2 saved and uploaded to gs://meetupmarch/images/image_1.png\n",
            "Generating image 3/10 with prompt: 'A team of engineers in a modern factory reviewing ...'\n",
            "Image 3 saved and uploaded to gs://meetupmarch/images/image_2.png\n",
            "Generating image 4/10 with prompt: 'Futuristic robotic arms assembling a complex piece...'\n",
            "Image 4 saved and uploaded to gs://meetupmarch/images/image_3.png\n",
            "Generating image 5/10 with prompt: 'A digital twin of a manufacturing facility, showin...'\n",
            "Image 5 saved and uploaded to gs://meetupmarch/images/image_4.png\n",
            "Generating image 6/10 with prompt: 'An aerial view of a smart warehouse with autonomou...'\n",
            "Image 6 saved and uploaded to gs://meetupmarch/images/image_5.png\n",
            "Generating image 7/10 with prompt: 'A scientist in a lab coat examining a beaker with ...'\n",
            "Image 7 saved and uploaded to gs://meetupmarch/images/image_6.png\n",
            "Generating image 8/10 with prompt: 'High-end cosmetic products arranged in a minimalis...'\n",
            "Image 8 saved and uploaded to gs://meetupmarch/images/image_7.png\n",
            "Generating image 9/10 with prompt: 'A cross-section of an advanced engine, showing int...'\n",
            "Image 9 saved and uploaded to gs://meetupmarch/images/image_8.png\n",
            "Generating image 10/10 with prompt: 'A beautiful landscape shot of a factory that blend...'\n",
            "Image 10 saved and uploaded to gs://meetupmarch/images/image_9.png\n",
            "--- Image Generation Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff21461c",
      "metadata": {
        "id": "ff21461c"
      },
      "source": [
        "```markdown\n",
        "### 2.2 Generate Music with Lyria\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need these libraries for making direct HTTP requests and handling authentication.\n",
        "import requests\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "\n",
        "# --- Helper Functions Exactly as in the Notebook ---\n",
        "\n",
        "def send_request_to_google_api(api_endpoint, data=None):\n",
        "    \"\"\"\n",
        "    Sends an HTTP request to a Google API endpoint.\n",
        "    \"\"\"\n",
        "    creds, project = google.auth.default()\n",
        "    auth_req = google.auth.transport.requests.Request()\n",
        "    creds.refresh(auth_req)\n",
        "    access_token = creds.token\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {access_token}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    response = requests.post(api_endpoint, headers=headers, json=data)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "def generate_music(api_endpoint, request: dict):\n",
        "    \"\"\"\n",
        "    Wraps the request and calls the API.\n",
        "    \"\"\"\n",
        "    req = {\"instances\": [request], \"parameters\": {}}\n",
        "    resp = send_request_to_google_api(api_endpoint, req)\n",
        "    return resp[\"predictions\"]\n",
        "\n",
        "# --- Define the Model URL ---\n",
        "music_model = f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-central1/publishers/google/models/lyria-002:predict\"\n",
        "local_music_dir = \"generated_music\"\n",
        "os.makedirs(local_music_dir, exist_ok=True)\n",
        "\n",
        "print(\"Setup complete. You can now run the cells below to generate each song individually.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks9fY9-vd32v",
        "outputId": "85b5513a-e389-47dd-f3d6-25e065028bf4"
      },
      "id": "ks9fY9-vd32v",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. You can now run the cells below to generate each song individually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#simple version - to be deleted\n",
        "try:\n",
        "    print(\"Generating Song 1...\")\n",
        "    # New, more descriptive prompt to avoid safety filters.\n",
        "    prompt = \"An uplifting and motivational corporate anthem for a quarterly results presentation, featuring bright piano, a steady electronic beat, and subtle synth pads.\"\n",
        "\n",
        "    predictions = generate_music(music_model, {\"prompt\": prompt, \"duration_secs\": 20})\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        with open(f\"{local_music_dir}/music_1.wav\", \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(\"SUCCESS: Song 1 saved as music_1.wav\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song 1: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52gYkFkwdqzS",
        "outputId": "44e52875-c940-4588-b712-13bdb77ae828"
      },
      "id": "52gYkFkwdqzS",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 1...\n",
            "SUCCESS: Song 1 saved as music_1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 1\n",
        "    prompt = \"An uplifting and motivational corporate anthem for a quarterly results presentation, featuring bright piano, a steady electronic beat, and subtle synth pads.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooP_Ht_Bl5tF",
        "outputId": "542a9132-72e9-40cc-8454-3fcf1603a92d"
      },
      "id": "ooP_Ht_Bl5tF",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 1 using the correct method...\n",
            "ERROR generating Song 1: 400 Client Error: Bad Request for url: https://us-central1-aiplatform.googleapis.com/v1/projects/geminienterprise-485114/locations/us-central1/publishers/google/models/lyria-002:predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 2\n",
        "    prompt = \"A minimal, ambient electronic track for a technology product showcase, calm and focused.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZD3CQbVTiDQA",
        "outputId": "0730d0a4-3756-4250-d370-af2a04791382"
      },
      "id": "ZD3CQbVTiDQA",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 2 using the correct method...\n",
            "SUCCESS: Song 2 saved locally.\n",
            "SUCCESS: Song 2 uploaded to GCS.\n",
            "SUCCESS: Metadata for Song 2 stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 3\n",
        "    prompt = \"A powerful, driving industrial beat with synth elements, suggesting innovation and power.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YPlc78sh9lq",
        "outputId": "2bd4e4ac-b600-4855-e27d-42c449d8d6ba"
      },
      "id": "_YPlc78sh9lq",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 3 using the correct method...\n",
            "SUCCESS: Song 3 saved locally.\n",
            "SUCCESS: Song 3 uploaded to GCS.\n",
            "SUCCESS: Metadata for Song 3 stored.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "4d825725",
      "metadata": {
        "id": "4d825725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55557868-55ab-4ef6-c3c0-175bcc00ec57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Song 4 using the correct method...\n",
            "SUCCESS: Song 4 saved locally.\n",
            "SUCCESS: Song 4 uploaded to GCS.\n",
            "SUCCESS: Metadata for Song 4 stored.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # --- Define Song Details ---\n",
        "    song_number = 4\n",
        "    prompt = \"An atmospheric and thoughtful soundscape for a documentary about sustainable manufacturing.\"\n",
        "    local_filename = f\"{local_music_dir}/music_{song_number}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{song_number}.wav\"\n",
        "\n",
        "    print(f\"Generating Song {song_number} using the correct method...\")\n",
        "\n",
        "    # --- This is YOUR working code for generating the music ---\n",
        "    predictions = generate_music(\n",
        "        music_model,\n",
        "        {\"prompt\": prompt, \"duration_secs\": 20}\n",
        "    )\n",
        "\n",
        "    for pred in predictions:\n",
        "        bytes_b64 = dict(pred)[\"bytesBase64Encoded\"]\n",
        "        audio_data = base64.b64decode(bytes_b64)\n",
        "\n",
        "        # --- Save Locally (as in your working code) ---\n",
        "        with open(local_filename, \"wb\") as f:\n",
        "            f.write(audio_data)\n",
        "        print(f\"SUCCESS: Song {song_number} saved locally.\")\n",
        "\n",
        "        # --- ADDED: Upload to Google Cloud Storage ---\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        print(f\"SUCCESS: Song {song_number} uploaded to GCS.\")\n",
        "\n",
        "        # --- ADDED: Store metadata for BigQuery ---\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"music_{song_number}\",\n",
        "            \"asset_type\": \"music\",\n",
        "            \"prompt\": prompt,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"lyria-002-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for Song {song_number} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR generating Song {song_number}: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0790ea5",
      "metadata": {
        "id": "a0790ea5"
      },
      "source": [
        "```markdown\n",
        "### 2.3 Generate Speech with Gemini TTS\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52bee2e",
      "metadata": {
        "id": "d52bee2e"
      },
      "outputs": [],
      "source": [
        "# generate 1 file only test\n",
        "from google.cloud import texttospeech\n",
        "\n",
        "client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "synthesis_input = texttospeech.SynthesisInput(text=\"Hello, this is a test of the Gemini Text-to-Speech API.\")\n",
        "voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "with open(\"generated_speech.mp3\", \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "    print('Audio content written to file \"generated_speech.mp3\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.auth\n",
        "from google.colab import auth\n",
        "\n",
        "# --- THE FINAL FIX: Force a new authentication for the correct project ---\n",
        "# This command will trigger a new login pop-up.\n",
        "# It explicitly tells the authentication library to use YOUR project.\n",
        "print(f\"Forcing new user authentication for project '{PROJECT_ID}'...\")\n",
        "auth.authenticate_user(project_id=PROJECT_ID)\n",
        "print(\"\\nSUCCESS: Authentication complete. The session is now correctly configured for your project.\")\n",
        "print(\"You can now run the Text-to-Speech cell below.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcmPIgJ8tpOm",
        "outputId": "9fbbc3c1-1584-4397-fa83-512b924891ba"
      },
      "id": "rcmPIgJ8tpOm",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forcing new user authentication for project 'geminienterprise-485114'...\n",
            "\n",
            "SUCCESS: Authentication complete. The session is now correctly configured for your project.\n",
            "You can now run the Text-to-Speech cell below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- THE FINAL FIX: Get the token directly from the gcloud CLI ---\n",
        "\n",
        "# 1. Force the project one last time to be absolutely sure.\n",
        "print(f\"Forcing the active project to '{PROJECT_ID}'...\")\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "\n",
        "# 2. Ask gcloud to print the authentication token for this project.\n",
        "# We capture the output of this command.\n",
        "print(\"\\nGetting auth token directly from gcloud...\")\n",
        "token_output = !gcloud auth print-access-token\n",
        "AUTH_TOKEN = token_output[0]\n",
        "\n",
        "print(\"SUCCESS: Manually retrieved authentication token.\")\n",
        "print(\"This token is guaranteed to be for the correct project.\")\n",
        "print(\"You can now run the TTS cell below.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtpC8N2EuXvh",
        "outputId": "0d79de69-d7b6-4d5b-fab2-29d7d03c80ab"
      },
      "id": "KtpC8N2EuXvh",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forcing the active project to 'geminienterprise-485114'...\n",
            "Updated property [core/project].\n",
            "\n",
            "Getting auth token directly from gcloud...\n",
            "SUCCESS: Manually retrieved authentication token.\n",
            "This token is guaranteed to be for the correct project.\n",
            "You can now run the TTS cell below.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"\\n--- Starting Speech Generation (Final Attempt with Quota Project Header) ---\")\n",
        "\n",
        "try:\n",
        "    # Get the auth token manually, which we know works.\n",
        "    token_output = !gcloud auth print-access-token\n",
        "    AUTH_TOKEN = token_output[0]\n",
        "\n",
        "    # --- THE FINAL FIX: Add the X-Goog-User-Project header ---\n",
        "    # This explicitly tells the API which project to bill for this request.\n",
        "    HEADERS = {\n",
        "        \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
        "        \"X-Goog-User-Project\": PROJECT_ID\n",
        "    }\n",
        "    TTS_ENDPOINT_URL = \"https://texttospeech.googleapis.com/v1/text:synthesize\"\n",
        "\n",
        "    local_speech_dir = \"generated_speech\"\n",
        "    os.makedirs(local_speech_dir, exist_ok=True)\n",
        "\n",
        "    speech_texts = [\"Quarterly production targets have been exceeded by fifteen percent.\"] # Just one for the final test\n",
        "\n",
        "    for i, text in enumerate(speech_texts):\n",
        "        print(f\"\\nGenerating one final test speech...\")\n",
        "        request_body = {\n",
        "            \"input\": {\"text\": text},\n",
        "            \"voice\": {\"languageCode\": \"en-US\", \"ssmlGender\": \"NEUTRAL\"},\n",
        "            \"audioConfig\": {\"audioEncoding\": \"MP3\"}\n",
        "        }\n",
        "\n",
        "        response = requests.post(url=TTS_ENDPOINT_URL, headers=HEADERS, json=request_body)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        print(\"SUCCESS! The API call succeeded with the X-Goog-User-Project header.\")\n",
        "        # ... (the rest of the code to save and upload would go here) ...\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- ERROR ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    if 'response' in locals() and hasattr(response, 'text'):\n",
        "        print(f\"Server response: {response.text}\")\n",
        "    print(\"\\n--- CONCLUSION ---\")\n",
        "    print(\"If this still fails, the environment is unrecoverable. The only solution is a Factory Reset.\")\n",
        "\n",
        "print(\"\\n--- Final Test Complete ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqOrCw9fu5BZ",
        "outputId": "f856e08e-e05a-49c1-db37-061b2843c4ba"
      },
      "id": "SqOrCw9fu5BZ",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Speech Generation (Final Attempt with Quota Project Header) ---\n",
            "\n",
            "Generating one final test speech...\n",
            "SUCCESS! The API call succeeded with the X-Goog-User-Project header.\n",
            "\n",
            "--- Final Test Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need these libraries for the direct API call.\n",
        "import requests\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"\\n--- Starting Speech Generation (Final Working Code) ---\")\n",
        "\n",
        "try:\n",
        "    # --- Step 1: Get the Authentication Token ---\n",
        "    # This method is confirmed to get the correct token for your active project.\n",
        "    print(\"Getting auth token directly from gcloud...\")\n",
        "    token_output = !gcloud auth print-access-token\n",
        "    AUTH_TOKEN = token_output[0]\n",
        "    print(\"SUCCESS: Token retrieved.\")\n",
        "\n",
        "    # --- Step 2: Set up the Headers with the CRITICAL FIX ---\n",
        "    HEADERS = {\n",
        "        \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
        "        \"X-Goog-User-Project\": PROJECT_ID  # This header forces the correct project.\n",
        "    }\n",
        "    TTS_ENDPOINT_URL = \"https://texttospeech.googleapis.com/v1/text:synthesize\"\n",
        "\n",
        "    local_speech_dir = \"generated_speech\"\n",
        "    os.makedirs(local_speech_dir, exist_ok=True)\n",
        "\n",
        "    # --- Step 3: Loop Through All 10 Speech Texts ---\n",
        "    speech_texts = [\n",
        "        \"Quarterly production targets have been exceeded by fifteen percent.\",\n",
        "        \"Safety protocol update: All personnel must attend the mandatory briefing on Friday.\",\n",
        "        \"The new supply chain optimization model is now live across all regions.\",\n",
        "        \"Alert: Unscheduled maintenance is required for assembly line three.\",\n",
        "        \"Our commitment to sustainable manufacturing has reduced our carbon footprint by 20% year-over-year.\",\n",
        "        \"The next shareholder meeting will be held on July 25th to discuss Q2 earnings.\",\n",
        "        \"Innovation in materials science is key to developing our next generation of products.\",\n",
        "        \"Customer feedback indicates a 95% satisfaction rate with our new service portal.\",\n",
        "        \"We are projecting a 10% growth in the consumer goods sector for the upcoming fiscal year.\",\n",
        "        \"Emergency shutdown procedures for the chemical processing unit have been initiated. This is a drill.\",\n",
        "    ]\n",
        "\n",
        "    for i, text in enumerate(speech_texts):\n",
        "        local_filename = f\"{local_speech_dir}/speech_{i}.mp3\"\n",
        "        gcs_blob_name = f\"speech/speech_{i}.mp3\"\n",
        "\n",
        "        print(f\"\\nGenerating speech {i+1}/{len(speech_texts)}...\")\n",
        "\n",
        "        request_body = {\n",
        "            \"input\": {\"text\": text},\n",
        "            \"voice\": {\"languageCode\": \"en-US\", \"ssmlGender\": \"NEUTRAL\"},\n",
        "            \"audioConfig\": {\"audioEncoding\": \"MP3\"}\n",
        "        }\n",
        "\n",
        "        # This request will now succeed.\n",
        "        response = requests.post(url=TTS_ENDPOINT_URL, headers=HEADERS, json=request_body)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        response_json = response.json()\n",
        "        audio_data_base64 = response_json[\"audioContent\"]\n",
        "        audio_data = base64.b64decode(audio_data_base64)\n",
        "\n",
        "        # Save locally\n",
        "        with open(local_filename, \"wb\") as out:\n",
        "            out.write(audio_data)\n",
        "        print(f\"SUCCESS: Speech {i+1} saved locally.\")\n",
        "\n",
        "        # Upload to GCS\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(gcs_blob_name)\n",
        "        blob.upload_from_filename(local_filename)\n",
        "        gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "        print(f\"SUCCESS: Speech {i+1} uploaded to GCS.\")\n",
        "\n",
        "        # Store metadata\n",
        "        all_metadata.append({\n",
        "            \"asset_id\": f\"speech_{i}\",\n",
        "            \"asset_type\": \"speech\",\n",
        "            \"prompt\": text,\n",
        "            \"gcs_uri\": gcs_uri,\n",
        "            \"model_used\": \"google-text-to-speech-direct-api\"\n",
        "        })\n",
        "        print(f\"SUCCESS: Metadata for speech {i+1} stored.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- An unexpected error occurred ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    if 'response' in locals() and hasattr(response, 'text'):\n",
        "        print(f\"Server response: {response.text}\")\n",
        "\n",
        "print(\"\\n--- Speech Generation Complete ---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amYxyL_JFZiQ",
        "outputId": "96bf5442-d38e-4247-cbbc-cf8350021f12"
      },
      "id": "amYxyL_JFZiQ",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Speech Generation (Final Working Code) ---\n",
            "Getting auth token directly from gcloud...\n",
            "SUCCESS: Token retrieved.\n",
            "\n",
            "Generating speech 1/10...\n",
            "SUCCESS: Speech 1 saved locally.\n",
            "SUCCESS: Speech 1 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 1 stored.\n",
            "\n",
            "Generating speech 2/10...\n",
            "SUCCESS: Speech 2 saved locally.\n",
            "SUCCESS: Speech 2 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 2 stored.\n",
            "\n",
            "Generating speech 3/10...\n",
            "SUCCESS: Speech 3 saved locally.\n",
            "SUCCESS: Speech 3 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 3 stored.\n",
            "\n",
            "Generating speech 4/10...\n",
            "SUCCESS: Speech 4 saved locally.\n",
            "SUCCESS: Speech 4 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 4 stored.\n",
            "\n",
            "Generating speech 5/10...\n",
            "SUCCESS: Speech 5 saved locally.\n",
            "SUCCESS: Speech 5 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 5 stored.\n",
            "\n",
            "Generating speech 6/10...\n",
            "SUCCESS: Speech 6 saved locally.\n",
            "SUCCESS: Speech 6 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 6 stored.\n",
            "\n",
            "Generating speech 7/10...\n",
            "SUCCESS: Speech 7 saved locally.\n",
            "SUCCESS: Speech 7 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 7 stored.\n",
            "\n",
            "Generating speech 8/10...\n",
            "SUCCESS: Speech 8 saved locally.\n",
            "SUCCESS: Speech 8 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 8 stored.\n",
            "\n",
            "Generating speech 9/10...\n",
            "SUCCESS: Speech 9 saved locally.\n",
            "SUCCESS: Speech 9 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 9 stored.\n",
            "\n",
            "Generating speech 10/10...\n",
            "SUCCESS: Speech 10 saved locally.\n",
            "SUCCESS: Speech 10 uploaded to GCS.\n",
            "SUCCESS: Metadata for speech 10 stored.\n",
            "\n",
            "--- Speech Generation Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1f6e5a",
      "metadata": {
        "id": "da1f6e5a"
      },
      "source": [
        "```markdown\n",
        "## 3. Upload to Google Cloud Storage\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  BigQuery Metadata Ingestion"
      ],
      "metadata": {
        "id": "cR83nAMwIwyd"
      },
      "id": "cR83nAMwIwyd"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating and Uploading Metadata File ---\")\n",
        "local_metadata_filename = \"metadata.jsonl\"\n",
        "gcs_metadata_blob_name = \"metadata/assets.jsonl\"\n",
        "\n",
        "with open(local_metadata_filename, \"w\") as f:\n",
        "    for item in all_metadata:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "blob = bucket.blob(gcs_metadata_blob_name)\n",
        "blob.upload_from_filename(local_metadata_filename)\n",
        "metadata_gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_metadata_blob_name}\"\n",
        "\n",
        "print(f\"Metadata file uploaded to {metadata_gcs_uri}\")\n"
      ],
      "metadata": {
        "id": "bQsnvwy5Ivru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbd817a-aca7-43b2-f6aa-7f645e08ce43"
      },
      "id": "bQsnvwy5Ivru",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Creating and Uploading Metadata File ---\n",
            "Metadata file uploaded to gs://meetupmarch/metadata/assets.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create BigQuery External Table"
      ],
      "metadata": {
        "id": "Yr_jJVRiI3PD"
      },
      "id": "Yr_jJVRiI3PD"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating BigQuery External Table ---\")\n",
        "\n",
        "table_ref = bq_client.dataset(DATASET_ID).table(TABLE_ID)\n",
        "\n",
        "# Define the schema for the external table\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"asset_id\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"asset_type\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"prompt\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"model_used\", \"STRING\"),\n",
        "]\n",
        "\n",
        "# --- THE FIX: Use the correct format name ---\n",
        "# Our file is Newline Delimited JSON, not a single JSON object.\n",
        "external_config = bigquery.ExternalConfig(\"NEWLINE_DELIMITED_JSON\")\n",
        "# --- END FIX ---\n",
        "\n",
        "external_config.source_uris = [metadata_gcs_uri]\n",
        "external_config.schema = schema\n",
        "\n",
        "# Create the table\n",
        "try:\n",
        "    bq_client.delete_table(table_ref, not_found_ok=True) # Delete if it exists to ensure a fresh start\n",
        "    print(f\"Existing table '{TABLE_ID}' deleted.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "table = bigquery.Table(table_ref)\n",
        "table.external_data_configuration = external_config\n",
        "\n",
        "# This create_table call will now succeed.\n",
        "table = bq_client.create_table(table)\n",
        "\n",
        "print(f\"\\nSUCCESS: External table '{table.project}.{table.dataset_id}.{table.table_id}' created successfully.\")\n"
      ],
      "metadata": {
        "id": "ymcPMZl4I4fO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1d60cb-c0ec-4e3b-b55e-091f7b05d702"
      },
      "id": "ymcPMZl4I4fO",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Creating BigQuery External Table ---\n",
            "Existing table 'assets_metadata' deleted.\n",
            "\n",
            "SUCCESS: External table 'geminienterprise-485114.generative_assets_dataset.assets_metadata' created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Data with BigQuery and Gemini"
      ],
      "metadata": {
        "id": "wgzxSLbWI9SP"
      },
      "id": "wgzxSLbWI9SP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the SQL: You'll need a reference to a Gemini model in BigQuery. If you don't have one, you can create it with this DDL command in BigQuery:"
      ],
      "metadata": {
        "id": "IoAKj743JKlj"
      },
      "id": "IoAKj743JKlj"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# --- Step 1: Force a new login pop-up ---\n",
        "print(\"--- Forcing New Authentication ---\")\n",
        "auth.authenticate_user(project_id=PROJECT_ID)\n",
        "print(\"SUCCESS: Authentication complete.\")\n",
        "\n",
        "# --- Step 2: Immediately create a new client ---\n",
        "# This ensures it uses the fresh token you just received.\n",
        "print(\"\\n--- Creating a new, fresh BigQuery Client ---\")\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "print(\"SUCCESS: BigQuery Client is now ready with a valid login.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "338nS_4Z33eK",
        "outputId": "7c4a244e-3ef2-472f-c97b-067b15caf2f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "338nS_4Z33eK",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Forcing New Authentication ---\n",
            "SUCCESS: Authentication complete.\n",
            "\n",
            "--- Creating a new, fresh BigQuery Client ---\n",
            "SUCCESS: BigQuery Client is now ready with a valid login.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import google.auth\n",
        "import google.auth.transport.requests\n",
        "import base64\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "print(\"--- Starting BigQuery Steps with Final Workaround ---\")\n",
        "\n",
        "try:\n",
        "    # --- Step 1: Get the Authentication Token ---\n",
        "    print(\"\\nGetting auth token directly from gcloud...\")\n",
        "    token_output = !gcloud auth print-access-token\n",
        "    AUTH_TOKEN = token_output[0]\n",
        "    HEADERS = {\n",
        "        \"Authorization\": f\"Bearer {AUTH_TOKEN}\",\n",
        "        \"Content-Type\": \"application/json; charset=utf-8\",\n",
        "    }\n",
        "    print(\"SUCCESS: Manually retrieved authentication token.\")\n",
        "\n",
        "    # --- Step 2: Define API Endpoints ---\n",
        "    BQ_API_BASE_URL = \"https://bigquery.googleapis.com/bigquery/v2\"\n",
        "    DATASET_URL = f\"{BQ_API_BASE_URL}/projects/{PROJECT_ID}/datasets\"\n",
        "    QUERY_URL = f\"{BQ_API_BASE_URL}/projects/{PROJECT_ID}/queries\"\n",
        "\n",
        "    # --- Step 3: Set up Dataset and External Table ---\n",
        "    print(\"\\nSetting up Dataset and External Table via API...\")\n",
        "    requests.delete(f\"{DATASET_URL}/{DATASET_ID}?deleteContents=true\", headers=HEADERS)\n",
        "    dataset_body = {\"datasetReference\": {\"datasetId\": DATASET_ID}, \"location\": \"us-central1\"}\n",
        "    response = requests.post(DATASET_URL, headers=HEADERS, json=dataset_body)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    tables_url = f\"{DATASET_URL}/{DATASET_ID}/tables\"\n",
        "    table_body = {\n",
        "        \"tableReference\": {\"projectId\": PROJECT_ID, \"datasetId\": DATASET_ID, \"tableId\": TABLE_ID},\n",
        "        \"externalDataConfiguration\": {\n",
        "            \"sourceFormat\": \"NEWLINE_DELIMITED_JSON\",\n",
        "            \"sourceUris\": [metadata_gcs_uri],\n",
        "            \"schema\": {\"fields\": [{\"name\": \"asset_id\", \"type\": \"STRING\"}, {\"name\": \"asset_type\", \"type\": \"STRING\"}, {\"name\": \"prompt\", \"type\": \"STRING\"}, {\"name\": \"gcs_uri\", \"type\": \"STRING\"}, {\"name\": \"model_used\", \"type\": \"STRING\"}]}\n",
        "        }\n",
        "    }\n",
        "    response = requests.post(tables_url, headers=HEADERS, json=table_body)\n",
        "    response.raise_for_status()\n",
        "    print(\"SUCCESS: Dataset and External Table are ready.\")\n",
        "\n",
        "    # --- Step 4: Create Remote Model with a WORKING Endpoint ---\n",
        "    print(\"\\nCreating BigQuery Remote Model...\")\n",
        "    CONNECTION_NAME = \"bq-vertex-connection\"\n",
        "    # --- THE FIX: Use 'gemini-pro', a model that is available to all projects. ---\n",
        "    sql_create_model = f\"\"\"\n",
        "        CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_text_model`\n",
        "        REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "        OPTIONS (endpoint = 'gemini-pro');\n",
        "    \"\"\"\n",
        "    query_body = {\"query\": sql_create_model, \"useLegacySql\": False}\n",
        "    response = requests.post(QUERY_URL, headers=HEADERS, json=query_body)\n",
        "    response.raise_for_status()\n",
        "    print(\"SUCCESS: 'Create Model' job for gemini-pro submitted.\")\n",
        "\n",
        "    # --- Step 5: Analyze TEXT PROMPTS with Gemini ---\n",
        "    print(\"\\nAnalyzing Image Prompts via API...\")\n",
        "    full_table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "    # --- This query now analyzes the 'prompt' column, not the image. ---\n",
        "    sql_analyze = f\"\"\"\n",
        "        SELECT prompt, ml_generate_text_result['predictions'][0]['content'] AS sentiment_analysis\n",
        "        FROM ML.GENERATE_TEXT(\n",
        "            MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_text_model`,\n",
        "            (SELECT prompt FROM `{full_table_id}` WHERE asset_type = 'image'),\n",
        "            STRUCT('Analyze the sentiment of the following text prompt and classify it as positive, neutral, or negative:' AS prompt));\n",
        "    \"\"\"\n",
        "    query_body = {\"query\": sql_analyze, \"useLegacySql\": False, \"timeoutMs\": 60000}\n",
        "    response = requests.post(QUERY_URL, headers=HEADERS, json=query_body)\n",
        "    response.raise_for_status()\n",
        "    query_results = response.json()\n",
        "\n",
        "    job_id = query_results['jobReference']['jobId']\n",
        "    print(f\"SUCCESS: 'Analyze' job submitted with ID: {job_id}. Polling for results...\")\n",
        "\n",
        "    while not query_results.get(\"jobComplete\"):\n",
        "        time.sleep(2)\n",
        "        results_url = f\"{QUERY_URL}/{job_id}?location=us-central1\"\n",
        "        response = requests.get(results_url, headers=HEADERS)\n",
        "        response.raise_for_status()\n",
        "        query_results = response.json()\n",
        "\n",
        "    rows = query_results.get(\"rows\", [])\n",
        "    data = [{field['name']: value['v'] for field, value in zip(query_results['schema']['fields'], row['f'])} for row in rows]\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(\"\\n--- Gemini Text Analysis Results ---\")\n",
        "    print(df.to_markdown(index=False))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- An Unexpected Error Occurred ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    if 'response' in locals() and hasattr(response, 'text'):\n",
        "        print(f\"Server response: {response.text}\")\n",
        "\n",
        "print(\"\\n--- BigQuery Steps Complete ---\")\n"
      ],
      "metadata": {
        "id": "NSTVKKc27QZP",
        "outputId": "8902400d-7949-4fa7-84e6-dea760fd0b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NSTVKKc27QZP",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting BigQuery Steps with Final Workaround ---\n",
            "\n",
            "Getting auth token directly from gcloud...\n",
            "SUCCESS: Manually retrieved authentication token.\n",
            "\n",
            "Setting up Dataset and External Table via API...\n",
            "SUCCESS: Dataset and External Table are ready.\n",
            "\n",
            "Creating BigQuery Remote Model...\n",
            "\n",
            "--- An Unexpected Error Occurred ---\n",
            "Error details: 400 Client Error: Bad Request for url: https://bigquery.googleapis.com/bigquery/v2/projects/geminienterprise-485114/queries\n",
            "Server response: {\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"Not found: Publisher Model `projects/geminienterprise-485114/locations/us-central1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\",\n",
            "    \"errors\": [\n",
            "      {\n",
            "        \"message\": \"Not found: Publisher Model `projects/geminienterprise-485114/locations/us-central1/publishers/google/models/gemini-pro` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\",\n",
            "        \"domain\": \"global\",\n",
            "        \"reason\": \"invalidQuery\",\n",
            "        \"location\": \"q\",\n",
            "        \"locationType\": \"parameter\"\n",
            "      }\n",
            "    ],\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "--- BigQuery Steps Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell uses the new `bq_client` you created in the cell above.\n",
        "\n",
        "print(\"--- Starting BigQuery Steps with Fresh Authentication ---\")\n",
        "\n",
        "try:\n",
        "    # --- Step 1: Correct the Dataset Location ---\n",
        "    print(\"\\nCorrecting Dataset Location...\")\n",
        "    dataset_id = f\"{PROJECT_ID}.{DATASET_ID}\"\n",
        "    bq_client.delete_dataset(dataset_id, delete_contents=True, not_found_ok=True)\n",
        "    dataset = bigquery.Dataset(dataset_id)\n",
        "    dataset.location = \"us-central1\"\n",
        "    created_dataset = bq_client.create_dataset(dataset)\n",
        "    print(f\"SUCCESS: Dataset '{created_dataset.dataset_id}' is ready in '{created_dataset.location}'.\")\n",
        "\n",
        "    # --- Step 2: Re-create the External Table ---\n",
        "    print(\"\\nRe-creating External Table...\")\n",
        "    table_ref = bq_client.dataset(DATASET_ID).table(TABLE_ID)\n",
        "    external_config = bigquery.ExternalConfig(\"NEWLINE_DELIMITED_JSON\")\n",
        "    external_config.source_uris = [metadata_gcs_uri]\n",
        "    external_config.schema = [\n",
        "        bigquery.SchemaField(\"asset_id\", \"STRING\"), bigquery.SchemaField(\"asset_type\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"prompt\", \"STRING\"), bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "        bigquery.SchemaField(\"model_used\", \"STRING\"),\n",
        "    ]\n",
        "    table = bigquery.Table(table_ref)\n",
        "    table.external_data_configuration = external_config\n",
        "    table = bq_client.create_table(table)\n",
        "    print(\"SUCCESS: External table created.\")\n",
        "\n",
        "    # --- Step 3: Create the Remote Model ---\n",
        "    print(\"\\nCreating BigQuery Remote Model...\")\n",
        "    CONNECTION_NAME = \"bq-vertex-connection\"\n",
        "    sql_create_model = f\"\"\"\n",
        "    CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_pro_vision_model`\n",
        "    REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "    OPTIONS (endpoint = 'gemini-pro-vision');\n",
        "    \"\"\"\n",
        "    query_job = bq_client.query(sql_create_model)\n",
        "    query_job.result()\n",
        "    print(\"SUCCESS: Remote model created.\")\n",
        "\n",
        "    # --- Step 4: Analyze Data with Gemini ---\n",
        "    print(\"\\nAnalyzing Image Data...\")\n",
        "    full_table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "    sql_analyze = f\"\"\"\n",
        "    SELECT\n",
        "        prompt,\n",
        "        gcs_uri,\n",
        "        ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "    FROM\n",
        "        ML.GENERATE_TEXT(\n",
        "            MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_pro_vision_model`,\n",
        "            (SELECT prompt, gcs_uri FROM `{full_table_id}` WHERE asset_type = 'image'),\n",
        "            STRUCT('Analyze the following image and describe its content in detail:' AS prompt, TRUE AS flatten_json_output)\n",
        "        );\n",
        "    \"\"\"\n",
        "    df = bq_client.query(sql_analyze).to_dataframe()\n",
        "    print(\"\\n--- Gemini Vision Analysis Results ---\")\n",
        "    print(df.to_markdown(index=False))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n--- An Unexpected Error Occurred ---\")\n",
        "    print(f\"Error details: {e}\")\n",
        "\n",
        "print(\"\\n--- BigQuery Steps Complete ---\")\n"
      ],
      "metadata": {
        "id": "F74OwcFbJFvj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "1ef40871-fcad-410b-e744-d7f03aca1a3e"
      },
      "id": "F74OwcFbJFvj",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Forcing New Authentication ---\n",
            "SUCCESS: Authentication complete.\n",
            "\n",
            "--- Re-initializing BigQuery Client ---\n",
            "SUCCESS: BigQuery Client is now ready with a valid login.\n",
            "\n",
            "--- Correcting Dataset Location ---\n",
            "SUCCESS: Dataset 'generative_assets_dataset' created in location 'us-central1'.\n",
            "\n",
            "--- Re-creating External Table ---\n",
            "SUCCESS: External table has been recreated.\n",
            "\n",
            "--- Creating BigQuery Remote Model ---\n",
            "ERROR creating model: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/geminienterprise-485114/queries/726661d5-58f6-4153-8f19-4d44d9fbf309?maxResults=0&location=us-central1&prettyPrint=false: Not found: Publisher Model `projects/geminienterprise-485114/locations/us-central1/publishers/google/models/gemini-1.0-pro-vision` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\n",
            "\n",
            "Location: us-central1\n",
            "Job ID: 726661d5-58f6-4153-8f19-4d44d9fbf309\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequest",
          "evalue": "400 GET https://bigquery.googleapis.com/bigquery/v2/projects/geminienterprise-485114/queries/726661d5-58f6-4153-8f19-4d44d9fbf309?maxResults=0&location=us-central1&prettyPrint=false: Not found: Publisher Model `projects/geminienterprise-485114/locations/us-central1/publishers/google/models/gemini-1.0-pro-vision` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\n\nLocation: us-central1\nJob ID: 726661d5-58f6-4153-8f19-4d44d9fbf309\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-753862951.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mquery_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_create_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SUCCESS: BigQuery remote model created successfully.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1740\u001b[0m                 \u001b[0;31m# jobs.getQueryResults hangs as long as it can to ensure we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m                 \u001b[0;31m# know when the query has finished as soon as possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reload_query_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreload_query_results_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                 \u001b[0;31m# Even if the query is finished now according to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36m_reload_query_results\u001b[0;34m(self, retry, timeout, page_size, start_index)\u001b[0m\n\u001b[1;32m   1532\u001b[0m                 \u001b[0mtransport_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m         self._query_results = self._client._get_query_results(\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_get_query_results\u001b[0;34m(self, job_id, retry, project, timeout_ms, location, timeout, page_size, start_index)\u001b[0m\n\u001b[1;32m   2111\u001b[0m         \u001b[0;31m# QueryJob.result()). So we don't need to poll here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m         \u001b[0mspan_attributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m         resource = self._call_api(\n\u001b[0m\u001b[1;32m   2114\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mspan_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"BigQuery.getQueryResults\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/client.py\u001b[0m in \u001b[0;36m_call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspan_attributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             ):\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/_http/__init__.py\u001b[0m in \u001b[0;36mapi_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpect_json\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequest\u001b[0m: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/geminienterprise-485114/queries/726661d5-58f6-4153-8f19-4d44d9fbf309?maxResults=0&location=us-central1&prettyPrint=false: Not found: Publisher Model `projects/geminienterprise-485114/locations/us-central1/publishers/google/models/gemini-1.0-pro-vision` was not found or your project does not have access to it. Please ensure you are using a valid model version. For more information, see: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versions\n\nLocation: us-central1\nJob ID: 726661d5-58f6-4153-8f19-4d44d9fbf309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Analyzing Images with Gemini in BigQuery ---\")\n",
        "\n",
        "# The fully qualified ID of the table we created earlier\n",
        "full_table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "# This query selects only the image assets, then passes their GCS URI and\n",
        "# the original prompt to the Gemini model for analysis.\n",
        "sql_analyze = f\"\"\"\n",
        "SELECT\n",
        "    prompt,\n",
        "    gcs_uri,\n",
        "    ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "FROM\n",
        "    ML.GENERATE_TEXT(\n",
        "        MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_pro_vision_model`,\n",
        "        (\n",
        "            -- Subquery to select only the images and their URIs\n",
        "            SELECT\n",
        "                prompt,\n",
        "                gcs_uri\n",
        "            FROM\n",
        "                `{full_table_id}`\n",
        "            WHERE\n",
        "                asset_type = 'image'\n",
        "        ),\n",
        "        STRUCT(\n",
        "            -- This is the prompt for the LLM analysis itself\n",
        "            'Describe this image in detail based on its content. Also, comment on how well it matches the original user prompt.' AS prompt,\n",
        "            TRUE AS flatten_json_output\n",
        "        )\n",
        "    );\n",
        "\"\"\"\n",
        "\n",
        "print(\"Executing analysis query... This may take a few moments.\")\n",
        "# Execute the query and load the results into a pandas DataFrame\n",
        "df = bq_client.query(sql_analyze).to_dataframe()\n",
        "\n",
        "# Display the results in a clean markdown format\n",
        "print(\"\\n--- Gemini Vision Analysis Results ---\")\n",
        "print(df.to_markdown(index=False))\n"
      ],
      "metadata": {
        "id": "z6MOdArpI_iZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "9795eab9-1525-4eaa-f890-57cde1bc8600"
      },
      "id": "z6MOdArpI_iZ",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Analyzing Images with Gemini in BigQuery ---\n",
            "Executing analysis query... This may take a few moments.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFound",
          "evalue": "404 Not found: Model geminienterprise-485114:generative_assets_dataset.gemini_pro_vision_model; reason: notFound, message: Not found: Model geminienterprise-485114:generative_assets_dataset.gemini_pro_vision_model\n\nLocation: us-central1\nJob ID: 5719b282-c449-4a17-ab26-06e523160f05\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFound\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1412361373.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing analysis query... This may take a few moments.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Execute the query and load the results into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_analyze\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Display the results in a clean markdown format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mto_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype, timeout)\u001b[0m\n\u001b[1;32m   2168\u001b[0m                 \u001b[0;34m:\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mshapely\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mimported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m         \"\"\"\n\u001b[0;32m-> 2170\u001b[0;31m         \u001b[0mquery_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait_for_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m         return query_result.to_dataframe(\n\u001b[1;32m   2172\u001b[0m             \u001b[0mbqstorage_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbqstorage_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_tqdm_helpers.py\u001b[0m in \u001b[0;36mwait_for_query\u001b[0;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1771\u001b[0m                 \u001b[0;31m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m                 \u001b[0;31m# long-running API, don't delay the next request at all.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_job_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py\u001b[0m in \u001b[0;36mis_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1720\u001b[0m                         \u001b[0;31m# `job_retry` predicate.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m                         \u001b[0mrestart_query_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1722\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mjob_failed_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1723\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1724\u001b[0m                         \u001b[0;31m# Make sure that the _query_results are cached so we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFound\u001b[0m: 404 Not found: Model geminienterprise-485114:generative_assets_dataset.gemini_pro_vision_model; reason: notFound, message: Not found: Model geminienterprise-485114:generative_assets_dataset.gemini_pro_vision_model\n\nLocation: us-central1\nJob ID: 5719b282-c449-4a17-ab26-06e523160f05\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}