{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7fc0848",
      "metadata": {
        "id": "f7fc0848"
      },
      "source": [
        "# generate assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5306947",
      "metadata": {
        "id": "b5306947"
      },
      "outputs": [],
      "source": [
        "GOOGLE_GENAI_USE_VERTEXAI=1\n",
        "GOOGLE_CLOUD_PROJECT=geminienterprise-485114\n",
        "GOOGLE_CLOUD_LOCATION=us-central1\n",
        "\n",
        "BIGQUERY_DATASET_NAME=\"\"\n",
        "BIGQUERY_LOCATION=\"\"\n",
        "BIGQUERY_CONNECTION_NAME=\"\"\n",
        "BIGQUERY_MODEL_OBJ_NAME=\"\"\n",
        "BIGQUERY_EMB_MODEL_OBJ_NAME=\"\"\n",
        "BIGQUERY_RESERVATION_NAME=\"\"\n",
        "SPANNER_INSTANCE_ID=\"\"\n",
        "SPANNER_DATABASE_ID=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c9e55cb",
      "metadata": {
        "id": "5c9e55cb"
      },
      "source": [
        "\n",
        "\n",
        "```markdown\n",
        "# BigQuery & Gemini: Generating and Analyzing Multimodal Data\n",
        "\n",
        "This notebook demonstrates how to use Vertex AI's generative models to create a multimodal dataset, store it in Google Cloud Storage, and then analyze it using BigQuery and Gemini.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf2909",
      "metadata": {
        "id": "5bcf2909"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 1. Setup and Installation\n",
        "\n",
        "First, let's install the necessary Python libraries for interacting with Google Cloud services.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a7ed3e2",
      "metadata": {
        "id": "8a7ed3e2",
        "outputId": "a8e9cc3e-543a-4783-ff80-5744dfad730d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.40.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (26.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.78.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d620d1c",
      "metadata": {
        "id": "1d620d1c"
      },
      "source": [
        "\n",
        "```markdown\n",
        "Next, please fill in your Google Cloud project details and other configuration values below.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "from google.cloud import texttospeech, storage, bigquery\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "IT3gUkU_DjHz"
      },
      "id": "IT3gUkU_DjHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6aa8092f",
      "metadata": {
        "id": "6aa8092f"
      },
      "outputs": [],
      "source": [
        "#easy test - to be deleted later\n",
        "import os\n",
        "\n",
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "# Your Google Cloud Storage bucket name\n",
        "GCS_BUCKET = \" meetupmarch\"\n",
        "# Your BigQuery dataset name\n",
        "# BIGQUERY_DATASET = \"your_bigquery_dataset\"\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION --- RIGHT ONE ---- FOR MEETUP\n",
        "# Please fill in these values\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "LOCATION = \"us-central1\"  # e.g., 'us-central1'\n",
        "GCS_BUCKET_NAME = \"your-unique-gcs-bucket-name\" # Must be a globally unique name\n",
        "\n",
        "# Derived names\n",
        "DATASET_ID = \"generative_assets_dataset\"\n",
        "TABLE_ID = \"assets_metadata\"\n",
        "\n",
        "# --- INITIALIZE CLIENTS ---\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "tts_client = texttospeech.TextToSpeechClient()"
      ],
      "metadata": {
        "id": "PsomYsDzDexf"
      },
      "id": "PsomYsDzDexf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create GCS Bucket if it doesn't exist ---\n",
        "bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "if not bucket.exists():\n",
        "    bucket.create(location=LOCATION)\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' created.\")\n",
        "else:\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' already exists.\")\n"
      ],
      "metadata": {
        "id": "EzEj1qPBE8hx"
      },
      "id": "EzEj1qPBE8hx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create BigQuery Dataset if it doesn't exist ---\n",
        "dataset_ref = bq_client.dataset(DATASET_ID)\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{DATASET_ID}' already exists.\")\n",
        "except Exception:\n",
        "    bq_client.create_dataset(DATASET_ID)\n",
        "    print(f\"Dataset '{DATASET_ID}' created.\")\n"
      ],
      "metadata": {
        "id": "-Jr6cCWAE-WR"
      },
      "id": "-Jr6cCWAE-WR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A list to hold metadata for all generated assets\n",
        "all_metadata = []"
      ],
      "metadata": {
        "id": "t2X2M7ZmE_-U"
      },
      "id": "t2X2M7ZmE_-U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9da5ecfd",
      "metadata": {
        "id": "9da5ecfd"
      },
      "source": [
        "```markdown\n",
        "## 2. Data Generation with Vertex AI\n",
        "\n",
        "Now, let's generate some multimodal data using different Vertex AI models.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8d28fb",
      "metadata": {
        "id": "7f8d28fb"
      },
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 1 image\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ff521e6",
      "metadata": {
        "id": "1ff521e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88aabbf7-bca2-423a-cfc6-62306c44862c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image generated and saved as generated_image.png\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.vision_models import ImageGenerationModel\n",
        "\n",
        "# TODO: Specify your project ID and location\n",
        "# vertexai.init(project=\"your-project-id\", location=\"your-location\")\n",
        "\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "\n",
        "image_prompt = \"a futuristic banana-shaped spaceship flying through a nebula\"\n",
        "\n",
        "response = image_model.generate_images(prompt=image_prompt)\n",
        "\n",
        "# The response is a list of Image objects.\n",
        "# Access the first image directly and save it.\n",
        "response[0].save(\"generated_image.png\")\n",
        "\n",
        "print(\"Image generated and saved as generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 10 images\n",
        "```"
      ],
      "metadata": {
        "id": "VB7xoriXARcN"
      },
      "id": "VB7xoriXARcN"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Starting Image Generation (Imagen 3) ---\")\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "local_image_dir = \"generated_images\"\n",
        "os.makedirs(local_image_dir, exist_ok=True)\n",
        "\n",
        "image_prompts = [\n",
        "    \"A state-of-the-art chemical manufacturing plant at sunset, with clean energy sources visible.\",\n",
        "    \"Macro shot of a new, sustainable consumer goods product made from plant-based materials.\",\n",
        "    \"A team of engineers in a modern factory reviewing data on a holographic display.\",\n",
        "    \"Futuristic robotic arms assembling a complex piece of machinery with precision.\",\n",
        "    \"A digital twin of a manufacturing facility, showing real-time operational data streams.\",\n",
        "    \"An aerial view of a smart warehouse with autonomous forklifts and delivery drones.\",\n",
        "    \"A scientist in a lab coat examining a beaker with a glowing liquid.\",\n",
        "    \"High-end cosmetic products arranged in a minimalist, elegant composition.\",\n",
        "    \"A cross-section of an advanced engine, showing intricate inner workings.\",\n",
        "    \"A beautiful landscape shot of a factory that blends seamlessly with nature.\",\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(image_prompts):\n",
        "    local_filename = f\"{local_image_dir}/image_{i}.png\"\n",
        "    gcs_blob_name = f\"images/image_{i}.png\"\n",
        "\n",
        "    print(f\"Generating image {i+1}/10 with prompt: '{prompt[:50]}...'\")\n",
        "    response = image_model.generate_images(prompt=prompt)\n",
        "    response[0].save(local_filename)\n",
        "\n",
        "    # Upload to GCS\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "\n",
        "    # Store metadata\n",
        "    all_metadata.append({\n",
        "        \"asset_id\": f\"image_{i}\",\n",
        "        \"asset_type\": \"image\",\n",
        "        \"prompt\": prompt,\n",
        "        \"gcs_uri\": gcs_uri,\n",
        "        \"model_used\": \"imagen-3.0-generate-002\"\n",
        "    })\n",
        "    print(f\"Image {i+1} saved and uploaded to {gcs_uri}\")\n",
        "\n",
        "print(\"--- Image Generation Complete ---\")\n"
      ],
      "metadata": {
        "id": "ScAeOjp0ANp2"
      },
      "id": "ScAeOjp0ANp2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ff21461c",
      "metadata": {
        "id": "ff21461c"
      },
      "source": [
        "```markdown\n",
        "### 2.2 Generate Music with Lyria\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d825725",
      "metadata": {
        "id": "4d825725"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "# Using a text model as a placeholder for Lyria access which is more complex\n",
        "# This simulates generating a prompt for a music model\n",
        "music_prompt = \"A short, upbeat, futuristic synthwave track for a space video game.\"\n",
        "\n",
        "# In a real scenario, you would use the appropriate Lyria model endpoint here.\n",
        "# For this notebook, we will save the prompt as a text file to represent the music generation.\n",
        "with open(\"generated_music_prompt.txt\", \"w\") as f:\n",
        "    f.write(music_prompt)\n",
        "\n",
        "print(\"Music prompt saved as generated_music_prompt.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0790ea5",
      "metadata": {
        "id": "a0790ea5"
      },
      "source": [
        "```markdown\n",
        "### 2.3 Generate Speech with Gemini TTS\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52bee2e",
      "metadata": {
        "id": "d52bee2e"
      },
      "outputs": [],
      "source": [
        "# generate 1 file only test\n",
        "from google.cloud import texttospeech\n",
        "\n",
        "client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "synthesis_input = texttospeech.SynthesisInput(text=\"Hello, this is a test of the Gemini Text-to-Speech API.\")\n",
        "voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "with open(\"generated_speech.mp3\", \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "    print('Audio content written to file \"generated_speech.mp3\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 10 files\n",
        "print(\"\\n--- Starting Speech Generation (Text-to-Speech) ---\")\n",
        "local_speech_dir = \"generated_speech\"\n",
        "os.makedirs(local_speech_dir, exist_ok=True)\n",
        "\n",
        "speech_texts = [\n",
        "    \"Quarterly production targets have been exceeded by fifteen percent.\",\n",
        "    \"Safety protocol update: All personnel must attend the mandatory briefing on Friday.\",\n",
        "    \"The new supply chain optimization model is now live across all regions.\",\n",
        "    \"Alert: Unscheduled maintenance is required for assembly line three.\",\n",
        "    \"Our commitment to sustainable manufacturing has reduced our carbon footprint by 20% year-over-year.\",\n",
        "    \"The next shareholder meeting will be held on July 25th to discuss Q2 earnings.\",\n",
        "    \"Innovation in materials science is key to developing our next generation of products.\",\n",
        "    \"Customer feedback indicates a 95% satisfaction rate with our new service portal.\",\n",
        "    \"We are projecting a 10% growth in the consumer goods sector for the upcoming fiscal year.\",\n",
        "    \"Emergency shutdown procedures for the chemical processing unit have been initiated. This is a drill.\",\n",
        "]\n",
        "\n",
        "for i, text in enumerate(speech_texts):\n",
        "    local_filename = f\"{local_speech_dir}/speech_{i}.mp3\"\n",
        "    gcs_blob_name = f\"speech/speech_{i}.mp3\"\n",
        "\n",
        "    print(f\"Generating speech {i+1}/10 for text: '{text[:50]}...'\")\n",
        "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "    voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "    response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "    with open(local_filename, \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "\n",
        "    # Upload to GCS\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "\n",
        "    # Store metadata\n",
        "    all_metadata.append({\n",
        "        \"asset_id\": f\"speech_{i}\",\n",
        "        \"asset_type\": \"speech\",\n",
        "        \"prompt\": text,\n",
        "        \"gcs_uri\": gcs_uri,\n",
        "        \"model_used\": \"google-text-to-speech\"\n",
        "    })\n",
        "    print(f\"Speech {i+1} saved and uploaded to {gcs_uri}\")\n",
        "\n",
        "print(\"--- Speech Generation Complete ---\")\n"
      ],
      "metadata": {
        "id": "amYxyL_JFZiQ"
      },
      "id": "amYxyL_JFZiQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "da1f6e5a",
      "metadata": {
        "id": "da1f6e5a"
      },
      "source": [
        "```markdown\n",
        "## 3. Upload to Google Cloud Storage\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bf9d1d",
      "metadata": {
        "id": "b5bf9d1d"
      },
      "outputs": [],
      "source": [
        "# easy version\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(GCS_BUCKET)\n",
        "\n",
        "def upload_to_gcs(filename):\n",
        "    blob = bucket.blob(filename)\n",
        "    blob.upload_from_filename(filename)\n",
        "    return f\"gs://{GCS_BUCKET}/{filename}\"\n",
        "\n",
        "image_gcs_uri = upload_to_gcs(\"generated_image.png\")\n",
        "music_gcs_uri = upload_to_gcs(\"generated_music_prompt.txt\")\n",
        "speech_gcs_uri = upload_to_gcs(\"generated_speech.mp3\")\n",
        "\n",
        "print(f\"Image URI: {image_gcs_uri}\")\n",
        "print(f\"Music URI: {music_gcs_uri}\")\n",
        "print(f\"Speech URI: {speech_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c153e8",
      "metadata": {
        "id": "94c153e8"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 4. Create BigQuery Table\n",
        "\n",
        "Now we'll create a JSONL file with metadata about our generated assets and upload it to GCS. Then we'll create a BigQuery external table that points to this metadata file.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3591f259",
      "metadata": {
        "id": "3591f259"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "metadata = [\n",
        "    {\"prompt\": image_prompt, \"gcs_uri\": image_gcs_uri, \"type\": \"image\"},\n",
        "    {\"prompt\": music_prompt, \"gcs_uri\": music_gcs_uri, \"type\": \"music\"},\n",
        "    {\"prompt\": \"Hello, this is a test of the Gemini Text-to-Speech API.\", \"gcs_uri\": speech_gcs_uri, \"type\": \"speech\"}\n",
        "]\n",
        "\n",
        "with open(\"metadata.jsonl\", \"w\") as f:\n",
        "    for item in metadata:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "metadata_gcs_uri = upload_to_gcs(\"metadata.jsonl\")\n",
        "print(f\"Metadata GCS URI: {metadata_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a54793",
      "metadata": {
        "id": "a0a54793"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "dataset_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}\"\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_id)  # Make an API request.\n",
        "    print(f\"Dataset {dataset_id} already exists.\")\n",
        "except Exception:\n",
        "    dataset = bigquery.Dataset(dataset_id)\n",
        "    dataset.location = LOCATION\n",
        "    dataset = bq_client.create_dataset(dataset, timeout=30)\n",
        "    print(f\"Created dataset {PROJECT_ID}.{dataset.dataset_id}\")\n",
        "\n",
        "table_id = f\"{dataset_id}.multimodal_assets\"\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"prompt\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"type\", \"STRING\"),\n",
        "]\n",
        "\n",
        "external_config = bigquery.ExternalConfig(\"NEWLINE_DELIMITED_JSON\")\n",
        "external_config.source_uris = [metadata_gcs_uri]\n",
        "external_config.schema = schema\n",
        "table = bigquery.Table(table_id, schema=schema)\n",
        "table.external_data_configuration = external_config\n",
        "table = bq_client.create_table(table, exists_ok=True)\n",
        "\n",
        "print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d99e7f3",
      "metadata": {
        "id": "4d99e7f3"
      },
      "source": [
        "```markdown\n",
        "## 5. Analyze Data with BigQuery and Gemini\n",
        "\n",
        "Finally, we'll create a remote model in BigQuery that points to the Gemini Pro Vision model. This will allow us to analyze the images directly from BigQuery using SQL.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2b05e1",
      "metadata": {
        "id": "2b2b05e1"
      },
      "outputs": [],
      "source": [
        "# This step assumes you have a BigQuery connection to Vertex AI set up.\n",
        "# See: https://cloud.google.com/bigquery/docs/create-cloud-resource-connection\n",
        "CONNECTION_NAME = \"your-bq-connection-to-vertex-ai\"\n",
        "\n",
        "sql_create_model = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "OPTIONS (remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(sql_create_model)\n",
        "query_job.result()  # Wait for the job to complete\n",
        "print(\"BigQuery remote model created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc30d9b",
      "metadata": {
        "id": "6dc30d9b"
      },
      "outputs": [],
      "source": [
        "sql_analyze = f\"\"\"\n",
        "SELECT\n",
        "    prompt,\n",
        "    gcs_uri,\n",
        "    ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "FROM\n",
        "    ML.GENERATE_TEXT(\n",
        "        MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`,\n",
        "        (SELECT prompt, gcs_uri FROM `{table_id}` WHERE type = 'image'),\n",
        "        STRUCT('Analyze the following image:' AS prompt, TRUE AS flatten_json_output)\n",
        "    );\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(sql_analyze).to_dataframe()\n",
        "print(df.to_markdown())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}