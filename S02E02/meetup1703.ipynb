{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7fc0848",
      "metadata": {
        "id": "f7fc0848"
      },
      "source": [
        "# generate assets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c9e55cb",
      "metadata": {
        "id": "5c9e55cb"
      },
      "source": [
        "\n",
        "\n",
        "```markdown\n",
        "# BigQuery & Gemini: Generating and Analyzing Multimodal Data\n",
        "\n",
        "This notebook demonstrates how to use Vertex AI's generative models to create a multimodal dataset, store it in Google Cloud Storage, and then analyze it using BigQuery and Gemini.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf2909",
      "metadata": {
        "id": "5bcf2909"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 1. Setup and Installation\n",
        "\n",
        "First, let's install the necessary Python libraries for interacting with Google Cloud services.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a7ed3e2",
      "metadata": {
        "id": "8a7ed3e2",
        "outputId": "a8e9cc3e-543a-4783-ff80-5744dfad730d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /root/.local/lib/python3.12/site-packages (1.139.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (3.9.0)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.40.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.29.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.47.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.27.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (5.29.6)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (26.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.59.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.63.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.12.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.22.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.8.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.72.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.78.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.71.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.3)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (4.12.1)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.59.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-cloud-aiplatform) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d620d1c",
      "metadata": {
        "id": "1d620d1c"
      },
      "source": [
        "\n",
        "```markdown\n",
        "Next, please fill in your Google Cloud project details and other configuration values below.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "from google.cloud import texttospeech, storage, bigquery\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "id": "IT3gUkU_DjHz"
      },
      "id": "IT3gUkU_DjHz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6aa8092f",
      "metadata": {
        "id": "6aa8092f"
      },
      "outputs": [],
      "source": [
        "#easy test - to be deleted later\n",
        "import os\n",
        "\n",
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "# Your Google Cloud Storage bucket name\n",
        "GCS_BUCKET = \" meetupmarch\"\n",
        "# Your BigQuery dataset name\n",
        "# BIGQUERY_DATASET = \"your_bigquery_dataset\"\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication\n",
        "# --- AUTHENTICATE ---\n",
        "# Authenticate with Google Cloud. This is crucial for running in a Colab environment.\n",
        "# It will trigger a pop-up window to ask for your credentials and permissions.\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "7va3ErSQOKfg"
      },
      "id": "7va3ErSQOKfg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION FOR YOUR MEETUP ---\n",
        "# Define project-wide variables.\n",
        "import os\n",
        "import vertexai\n",
        "from google.cloud import texttospeech, storage, bigquery\n",
        "import json\n",
        "\n",
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Your Google Cloud Storage bucket name (no 'gs://' prefix)\n",
        "GCS_BUCKET_NAME = \"meetupmarch\"\n",
        "\n",
        "# Derived names for our BigQuery resources\n",
        "DATASET_ID = \"generative_assets_dataset\"\n",
        "TABLE_ID = \"assets_metadata\"\n",
        "\n",
        "# --- INITIALIZE CLIENTS ---\n",
        "# Initialize Vertex AI SDK and other clients with your project details.\n",
        "# After authentication, these clients will have the necessary permissions.\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)\n",
        "tts_client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "print(f\"Project: {PROJECT_ID}, Location: {LOCATION}\")\n",
        "print(\"Vertex AI and other Google Cloud clients initialized successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PsomYsDzDexf"
      },
      "id": "PsomYsDzDexf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- PREPARE GCS BUCKET AND BIGQUERY DATASET ---\n",
        "# This code will create the resources if they don't already exist.\n",
        "\n",
        "# GCS Bucket\n",
        "bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "if not bucket.exists():\n",
        "    bucket.create(location=LOCATION)\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' created.\")\n",
        "else:\n",
        "    print(f\"Bucket '{GCS_BUCKET_NAME}' already exists.\")"
      ],
      "metadata": {
        "id": "EzEj1qPBE8hx"
      },
      "id": "EzEj1qPBE8hx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BigQuery Dataset\n",
        "dataset_ref = bq_client.dataset(DATASET_ID)\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{DATASET_ID}' already exists.\")\n",
        "except Exception:\n",
        "    bq_client.create_dataset(dataset_ref)\n",
        "    print(f\"Dataset '{DATASET_ID}' created.\")\n"
      ],
      "metadata": {
        "id": "-Jr6cCWAE-WR"
      },
      "id": "-Jr6cCWAE-WR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A list to hold metadata for all generated assets\n",
        "all_metadata = []"
      ],
      "metadata": {
        "id": "t2X2M7ZmE_-U"
      },
      "id": "t2X2M7ZmE_-U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9da5ecfd",
      "metadata": {
        "id": "9da5ecfd"
      },
      "source": [
        "```markdown\n",
        "## 2. Data Generation with Vertex AI\n",
        "\n",
        "Now, let's generate some multimodal data using different Vertex AI models.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8d28fb",
      "metadata": {
        "id": "7f8d28fb"
      },
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 1 image\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1ff521e6",
      "metadata": {
        "id": "1ff521e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88aabbf7-bca2-423a-cfc6-62306c44862c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image generated and saved as generated_image.png\n"
          ]
        }
      ],
      "source": [
        "import vertexai\n",
        "from vertexai.vision_models import ImageGenerationModel\n",
        "\n",
        "# TODO: Specify your project ID and location\n",
        "# vertexai.init(project=\"your-project-id\", location=\"your-location\")\n",
        "\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "\n",
        "image_prompt = \"a futuristic banana-shaped spaceship flying through a nebula\"\n",
        "\n",
        "response = image_model.generate_images(prompt=image_prompt)\n",
        "\n",
        "# The response is a list of Image objects.\n",
        "# Access the first image directly and save it.\n",
        "response[0].save(\"generated_image.png\")\n",
        "\n",
        "print(\"Image generated and saved as generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen - 10 images\n",
        "```"
      ],
      "metadata": {
        "id": "VB7xoriXARcN"
      },
      "id": "VB7xoriXARcN"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Starting Image Generation (Imagen 3) ---\")\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-002\")\n",
        "local_image_dir = \"generated_images\"\n",
        "os.makedirs(local_image_dir, exist_ok=True)\n",
        "\n",
        "image_prompts = [\n",
        "    \"A state-of-the-art chemical manufacturing plant at sunset, with clean energy sources visible.\",\n",
        "    \"Macro shot of a new, sustainable consumer goods product made from plant-based materials.\",\n",
        "    \"A team of engineers in a modern factory reviewing data on a holographic display.\",\n",
        "    \"Futuristic robotic arms assembling a complex piece of machinery with precision.\",\n",
        "    \"A digital twin of a manufacturing facility, showing real-time operational data streams.\",\n",
        "    \"An aerial view of a smart warehouse with autonomous forklifts and delivery drones.\",\n",
        "    \"A scientist in a lab coat examining a beaker with a glowing liquid.\",\n",
        "    \"High-end cosmetic products arranged in a minimalist, elegant composition.\",\n",
        "    \"A cross-section of an advanced engine, showing intricate inner workings.\",\n",
        "    \"A beautiful landscape shot of a factory that blends seamlessly with nature.\",\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(image_prompts):\n",
        "    local_filename = f\"{local_image_dir}/image_{i}.png\"\n",
        "    gcs_blob_name = f\"images/image_{i}.png\"\n",
        "\n",
        "    print(f\"Generating image {i+1}/10 with prompt: '{prompt[:50]}...'\")\n",
        "    response = image_model.generate_images(prompt=prompt)\n",
        "    response[0].save(local_filename)\n",
        "\n",
        "    # Upload to GCS\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "\n",
        "    # Store metadata\n",
        "    all_metadata.append({\n",
        "        \"asset_id\": f\"image_{i}\",\n",
        "        \"asset_type\": \"image\",\n",
        "        \"prompt\": prompt,\n",
        "        \"gcs_uri\": gcs_uri,\n",
        "        \"model_used\": \"imagen-3.0-generate-002\"\n",
        "    })\n",
        "    print(f\"Image {i+1} saved and uploaded to {gcs_uri}\")\n",
        "\n",
        "print(\"--- Image Generation Complete ---\")\n"
      ],
      "metadata": {
        "id": "ScAeOjp0ANp2"
      },
      "id": "ScAeOjp0ANp2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ff21461c",
      "metadata": {
        "id": "ff21461c"
      },
      "source": [
        "```markdown\n",
        "### 2.2 Generate Music with Lyria\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d825725",
      "metadata": {
        "id": "4d825725"
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- Starting Music Generation (Lyria) ---\")\n",
        "from vertexai.preview.generative_models import GenerativeModel, MusicGenerationInput\n",
        "\n",
        "# --- CONFIGURATION for Lyria ---\n",
        "# As per the official Colab notebook, \"music-generation-preview\" is the correct model endpoint.\n",
        "lyria_model = GenerativeModel(\"music-generation-preview\")\n",
        "local_music_dir = \"generated_music\"\n",
        "os.makedirs(local_music_dir, exist_ok=True)\n",
        "\n",
        "# Prompts designed to evoke a corporate, industrial, or tech-focused mood\n",
        "music_prompts = [\n",
        "    \"An optimistic and inspiring corporate anthem, with a steady electronic beat and piano.\",\n",
        "    \"A minimal, ambient electronic track for a technology product showcase, calm and focused.\",\n",
        "    \"A powerful, driving industrial beat with synth elements, suggesting innovation and power.\",\n",
        "    \"An atmospheric and thoughtful soundscape for a documentary about sustainable manufacturing.\",\n",
        "    \"A futuristic, high-energy electronic track with a sense of speed and progress, for a product launch video.\",\n",
        "    \"A gentle, flowing piano and strings piece, evoking precision and care, for a chemical goods company ad.\",\n",
        "    \"An 8-bit chiptune track with a modern synth bassline, representing the gamification of enterprise software.\",\n",
        "    \"A tense, percussive track for a cybersecurity-themed video, creating a sense of urgency.\",\n",
        "    \"A warm, uplifting acoustic guitar track for an internal company video about teamwork and success.\",\n",
        "    \"A cinematic, orchestral piece with a grand and epic feel, for a brand story video.\",\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(music_prompts):\n",
        "    local_filename = f\"{local_music_dir}/music_{i}.wav\"\n",
        "    gcs_blob_name = f\"music/music_{i}.wav\"\n",
        "    clip_duration = 20  # Set a consistent duration for each clip\n",
        "\n",
        "    print(f\"Generating music {i+1}/10 with prompt: '{prompt[:50]}...'\")\n",
        "\n",
        "    # Use the structured MusicGenerationInput as shown in the Colab notebook\n",
        "    music_input = MusicGenerationInput(prompt=prompt, duration_secs=clip_duration)\n",
        "\n",
        "    # The generate_content method expects a list of inputs\n",
        "    response = lyria_model.generate_content([music_input])\n",
        "\n",
        "    # Safely extract the audio data by checking the MIME type, as recommended\n",
        "    audio_data = None\n",
        "    for part in response.candidates[0].content.parts:\n",
        "        if part.mime_type == \"audio/wav\":\n",
        "            audio_data = part.data\n",
        "            break\n",
        "\n",
        "    if not audio_data:\n",
        "        print(f\"Warning: Could not extract audio data for prompt {i+1}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Save the raw audio bytes to a file\n",
        "    with open(local_filename, \"wb\") as f:\n",
        "        f.write(audio_data)\n",
        "\n",
        "    # Upload to GCS\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "\n",
        "    # Store metadata with the correct model name\n",
        "    all_metadata.append({\n",
        "        \"asset_id\": f\"music_{i}\",\n",
        "        \"asset_type\": \"music\",\n",
        "        \"prompt\": prompt,\n",
        "        \"gcs_uri\": gcs_uri,\n",
        "        \"model_used\": \"music-generation-preview\" # Updated model name\n",
        "    })\n",
        "    print(f\"Music {i+1} saved and uploaded to {gcs_uri}\")\n",
        "\n",
        "print(\"--- Music Generation Complete ---\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0790ea5",
      "metadata": {
        "id": "a0790ea5"
      },
      "source": [
        "```markdown\n",
        "### 2.3 Generate Speech with Gemini TTS\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52bee2e",
      "metadata": {
        "id": "d52bee2e"
      },
      "outputs": [],
      "source": [
        "# generate 1 file only test\n",
        "from google.cloud import texttospeech\n",
        "\n",
        "client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "synthesis_input = texttospeech.SynthesisInput(text=\"Hello, this is a test of the Gemini Text-to-Speech API.\")\n",
        "voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "with open(\"generated_speech.mp3\", \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "    print('Audio content written to file \"generated_speech.mp3\"')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 10 files\n",
        "print(\"\\n--- Starting Speech Generation (Text-to-Speech) ---\")\n",
        "local_speech_dir = \"generated_speech\"\n",
        "os.makedirs(local_speech_dir, exist_ok=True)\n",
        "\n",
        "speech_texts = [\n",
        "    \"Quarterly production targets have been exceeded by fifteen percent.\",\n",
        "    \"Safety protocol update: All personnel must attend the mandatory briefing on Friday.\",\n",
        "    \"The new supply chain optimization model is now live across all regions.\",\n",
        "    \"Alert: Unscheduled maintenance is required for assembly line three.\",\n",
        "    \"Our commitment to sustainable manufacturing has reduced our carbon footprint by 20% year-over-year.\",\n",
        "    \"The next shareholder meeting will be held on July 25th to discuss Q2 earnings.\",\n",
        "    \"Innovation in materials science is key to developing our next generation of products.\",\n",
        "    \"Customer feedback indicates a 95% satisfaction rate with our new service portal.\",\n",
        "    \"We are projecting a 10% growth in the consumer goods sector for the upcoming fiscal year.\",\n",
        "    \"Emergency shutdown procedures for the chemical processing unit have been initiated. This is a drill.\",\n",
        "]\n",
        "\n",
        "for i, text in enumerate(speech_texts):\n",
        "    local_filename = f\"{local_speech_dir}/speech_{i}.mp3\"\n",
        "    gcs_blob_name = f\"speech/speech_{i}.mp3\"\n",
        "\n",
        "    print(f\"Generating speech {i+1}/10 for text: '{text[:50]}...'\")\n",
        "    synthesis_input = texttospeech.SynthesisInput(text=text)\n",
        "    voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "    response = tts_client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "    with open(local_filename, \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "\n",
        "    # Upload to GCS\n",
        "    blob = bucket.blob(gcs_blob_name)\n",
        "    blob.upload_from_filename(local_filename)\n",
        "    gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_blob_name}\"\n",
        "\n",
        "    # Store metadata\n",
        "    all_metadata.append({\n",
        "        \"asset_id\": f\"speech_{i}\",\n",
        "        \"asset_type\": \"speech\",\n",
        "        \"prompt\": text,\n",
        "        \"gcs_uri\": gcs_uri,\n",
        "        \"model_used\": \"google-text-to-speech\"\n",
        "    })\n",
        "    print(f\"Speech {i+1} saved and uploaded to {gcs_uri}\")\n",
        "\n",
        "print(\"--- Speech Generation Complete ---\")\n"
      ],
      "metadata": {
        "id": "amYxyL_JFZiQ"
      },
      "id": "amYxyL_JFZiQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "da1f6e5a",
      "metadata": {
        "id": "da1f6e5a"
      },
      "source": [
        "```markdown\n",
        "## 3. Upload to Google Cloud Storage\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bf9d1d",
      "metadata": {
        "id": "b5bf9d1d"
      },
      "outputs": [],
      "source": [
        "# easy version\n",
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(GCS_BUCKET)\n",
        "\n",
        "def upload_to_gcs(filename):\n",
        "    blob = bucket.blob(filename)\n",
        "    blob.upload_from_filename(filename)\n",
        "    return f\"gs://{GCS_BUCKET}/{filename}\"\n",
        "\n",
        "image_gcs_uri = upload_to_gcs(\"generated_image.png\")\n",
        "music_gcs_uri = upload_to_gcs(\"generated_music_prompt.txt\")\n",
        "speech_gcs_uri = upload_to_gcs(\"generated_speech.mp3\")\n",
        "\n",
        "print(f\"Image URI: {image_gcs_uri}\")\n",
        "print(f\"Music URI: {music_gcs_uri}\")\n",
        "print(f\"Speech URI: {speech_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  BigQuery Metadata Ingestion"
      ],
      "metadata": {
        "id": "cR83nAMwIwyd"
      },
      "id": "cR83nAMwIwyd"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating and Uploading Metadata File ---\")\n",
        "local_metadata_filename = \"metadata.jsonl\"\n",
        "gcs_metadata_blob_name = \"metadata/assets.jsonl\"\n",
        "\n",
        "with open(local_metadata_filename, \"w\") as f:\n",
        "    for item in all_metadata:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "blob = bucket.blob(gcs_metadata_blob_name)\n",
        "blob.upload_from_filename(local_metadata_filename)\n",
        "metadata_gcs_uri = f\"gs://{GCS_BUCKET_NAME}/{gcs_metadata_blob_name}\"\n",
        "\n",
        "print(f\"Metadata file uploaded to {metadata_gcs_uri}\")\n"
      ],
      "metadata": {
        "id": "bQsnvwy5Ivru"
      },
      "id": "bQsnvwy5Ivru",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create BigQuery External Table"
      ],
      "metadata": {
        "id": "Yr_jJVRiI3PD"
      },
      "id": "Yr_jJVRiI3PD"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating BigQuery External Table ---\")\n",
        "\n",
        "table_ref = dataset_ref.table(TABLE_ID)\n",
        "\n",
        "# Define the schema for the external table\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"asset_id\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"asset_type\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"prompt\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"model_used\", \"STRING\"),\n",
        "]\n",
        "\n",
        "external_config = bigquery.ExternalConfig(\"JSON\")\n",
        "external_config.source_uris = [metadata_gcs_uri]\n",
        "external_config.schema = schema\n",
        "# For JSONL, autodetect often works well, but explicit schema is safer.\n",
        "# external_config.autodetect = True\n",
        "\n",
        "# Create the table\n",
        "try:\n",
        "    bq_client.delete_table(table_ref, not_found_ok=True) # Delete if it exists to ensure a fresh start\n",
        "    print(f\"Existing table '{TABLE_ID}' deleted.\")\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "table = bigquery.Table(table_ref)\n",
        "table.external_data_configuration = external_config\n",
        "table = bq_client.create_table(table)\n",
        "\n",
        "print(f\"External table '{table.project}.{table.dataset_id}.{table.table_id}' created successfully.\")\n"
      ],
      "metadata": {
        "id": "ymcPMZl4I4fO"
      },
      "id": "ymcPMZl4I4fO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyze Data with BigQuery and Gemini"
      ],
      "metadata": {
        "id": "wgzxSLbWI9SP"
      },
      "id": "wgzxSLbWI9SP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before running the SQL: You'll need a reference to a Gemini model in BigQuery. If you don't have one, you can create it with this DDL command in BigQuery:"
      ],
      "metadata": {
        "id": "IoAKj743JKlj"
      },
      "id": "IoAKj743JKlj"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Creating BigQuery Remote Model ---\")\n",
        "\n",
        "# --- CONFIGURATION for BigQuery Connection ---\n",
        "# !!! IMPORTANT !!!\n",
        "# Please replace this with the actual ID of your BigQuery connection.\n",
        "# The connection must be created in the same location as your dataset (e.g., 'us-central1').\n",
        "CONNECTION_NAME = \"your-bq-connection-to-vertex-ai\" # e.g., \"bq-vertex-connection\"\n",
        "\n",
        "# Define the SQL query to create the remote model\n",
        "sql_create_model = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_pro_vision_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "OPTIONS (remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "\"\"\"\n",
        "\n",
        "print(\"Executing query to create or replace BigQuery remote model...\")\n",
        "# Execute the query using the BigQuery client\n",
        "query_job = bq_client.query(sql_create_model)\n",
        "query_job.result()  # Wait for the job to complete\n",
        "\n",
        "print(f\"BigQuery remote model `{DATASET_ID}.gemini_pro_vision_model` created or replaced successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "F74OwcFbJFvj"
      },
      "id": "F74OwcFbJFvj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Analyzing Images with Gemini in BigQuery ---\")\n",
        "\n",
        "# The fully qualified ID of the table we created earlier\n",
        "full_table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\"\n",
        "\n",
        "# This query selects only the image assets, then passes their GCS URI and\n",
        "# the original prompt to the Gemini model for analysis.\n",
        "sql_analyze = f\"\"\"\n",
        "SELECT\n",
        "    prompt,\n",
        "    gcs_uri,\n",
        "    ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "FROM\n",
        "    ML.GENERATE_TEXT(\n",
        "        MODEL `{PROJECT_ID}.{DATASET_ID}.gemini_pro_vision_model`,\n",
        "        (\n",
        "            -- Subquery to select only the images and their URIs\n",
        "            SELECT\n",
        "                prompt,\n",
        "                gcs_uri\n",
        "            FROM\n",
        "                `{full_table_id}`\n",
        "            WHERE\n",
        "                asset_type = 'image'\n",
        "        ),\n",
        "        STRUCT(\n",
        "            -- This is the prompt for the LLM analysis itself\n",
        "            'Describe this image in detail based on its content. Also, comment on how well it matches the original user prompt.' AS prompt,\n",
        "            TRUE AS flatten_json_output\n",
        "        )\n",
        "    );\n",
        "\"\"\"\n",
        "\n",
        "print(\"Executing analysis query... This may take a few moments.\")\n",
        "# Execute the query and load the results into a pandas DataFrame\n",
        "df = bq_client.query(sql_analyze).to_dataframe()\n",
        "\n",
        "# Display the results in a clean markdown format\n",
        "print(\"\\n--- Gemini Vision Analysis Results ---\")\n",
        "print(df.to_markdown(index=False))\n"
      ],
      "metadata": {
        "id": "z6MOdArpI_iZ"
      },
      "id": "z6MOdArpI_iZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "94c153e8",
      "metadata": {
        "id": "94c153e8"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 4. Create BigQuery Table\n",
        "\n",
        "Now we'll create a JSONL file with metadata about our generated assets and upload it to GCS. Then we'll create a BigQuery external table that points to this metadata file.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3591f259",
      "metadata": {
        "id": "3591f259"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "metadata = [\n",
        "    {\"prompt\": image_prompt, \"gcs_uri\": image_gcs_uri, \"type\": \"image\"},\n",
        "    {\"prompt\": music_prompt, \"gcs_uri\": music_gcs_uri, \"type\": \"music\"},\n",
        "    {\"prompt\": \"Hello, this is a test of the Gemini Text-to-Speech API.\", \"gcs_uri\": speech_gcs_uri, \"type\": \"speech\"}\n",
        "]\n",
        "\n",
        "with open(\"metadata.jsonl\", \"w\") as f:\n",
        "    for item in metadata:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "metadata_gcs_uri = upload_to_gcs(\"metadata.jsonl\")\n",
        "print(f\"Metadata GCS URI: {metadata_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a54793",
      "metadata": {
        "id": "a0a54793"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "dataset_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}\"\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_id)  # Make an API request.\n",
        "    print(f\"Dataset {dataset_id} already exists.\")\n",
        "except Exception:\n",
        "    dataset = bigquery.Dataset(dataset_id)\n",
        "    dataset.location = LOCATION\n",
        "    dataset = bq_client.create_dataset(dataset, timeout=30)\n",
        "    print(f\"Created dataset {PROJECT_ID}.{dataset.dataset_id}\")\n",
        "\n",
        "table_id = f\"{dataset_id}.multimodal_assets\"\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"prompt\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"type\", \"STRING\"),\n",
        "]\n",
        "\n",
        "external_config = bigquery.ExternalConfig(\"NEWLINE_DELIMITED_JSON\")\n",
        "external_config.source_uris = [metadata_gcs_uri]\n",
        "external_config.schema = schema\n",
        "table = bigquery.Table(table_id, schema=schema)\n",
        "table.external_data_configuration = external_config\n",
        "table = bq_client.create_table(table, exists_ok=True)\n",
        "\n",
        "print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d99e7f3",
      "metadata": {
        "id": "4d99e7f3"
      },
      "source": [
        "```markdown\n",
        "## 5. Analyze Data with BigQuery and Gemini\n",
        "\n",
        "Finally, we'll create a remote model in BigQuery that points to the Gemini Pro Vision model. This will allow us to analyze the images directly from BigQuery using SQL.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2b05e1",
      "metadata": {
        "id": "2b2b05e1"
      },
      "outputs": [],
      "source": [
        "# This step assumes you have a BigQuery connection to Vertex AI set up.\n",
        "# See: https://cloud.google.com/bigquery/docs/create-cloud-resource-connection\n",
        "CONNECTION_NAME = \"your-bq-connection-to-vertex-ai\"\n",
        "\n",
        "sql_create_model = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "OPTIONS (remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(sql_create_model)\n",
        "query_job.result()  # Wait for the job to complete\n",
        "print(\"BigQuery remote model created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc30d9b",
      "metadata": {
        "id": "6dc30d9b"
      },
      "outputs": [],
      "source": [
        "sql_analyze = f\"\"\"\n",
        "SELECT\n",
        "    prompt,\n",
        "    gcs_uri,\n",
        "    ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "FROM\n",
        "    ML.GENERATE_TEXT(\n",
        "        MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`,\n",
        "        (SELECT prompt, gcs_uri FROM `{table_id}` WHERE type = 'image'),\n",
        "        STRUCT('Analyze the following image:' AS prompt, TRUE AS flatten_json_output)\n",
        "    );\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(sql_analyze).to_dataframe()\n",
        "print(df.to_markdown())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}