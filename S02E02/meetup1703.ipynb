{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f7fc0848",
      "metadata": {
        "id": "f7fc0848"
      },
      "source": [
        "# generate assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5306947",
      "metadata": {
        "id": "b5306947"
      },
      "outputs": [],
      "source": [
        "GOOGLE_GENAI_USE_VERTEXAI=1\n",
        "GOOGLE_CLOUD_PROJECT=geminienterprise-485114\n",
        "GOOGLE_CLOUD_LOCATION=us-central1\n",
        "\n",
        "BIGQUERY_DATASET_NAME=\"\"\n",
        "BIGQUERY_LOCATION=\"\"\n",
        "BIGQUERY_CONNECTION_NAME=\"\"\n",
        "BIGQUERY_MODEL_OBJ_NAME=\"\"\n",
        "BIGQUERY_EMB_MODEL_OBJ_NAME=\"\"\n",
        "BIGQUERY_RESERVATION_NAME=\"\"\n",
        "SPANNER_INSTANCE_ID=\"\"\n",
        "SPANNER_DATABASE_ID=\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c9e55cb",
      "metadata": {
        "id": "5c9e55cb"
      },
      "source": [
        "\n",
        "\n",
        "```markdown\n",
        "# BigQuery & Gemini: Generating and Analyzing Multimodal Data\n",
        "\n",
        "This notebook demonstrates how to use Vertex AI's generative models to create a multimodal dataset, store it in Google Cloud Storage, and then analyze it using BigQuery and Gemini.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bcf2909",
      "metadata": {
        "id": "5bcf2909"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 1. Setup and Installation\n",
        "\n",
        "First, let's install the necessary Python libraries for interacting with Google Cloud services.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a7ed3e2",
      "metadata": {
        "id": "8a7ed3e2",
        "outputId": "8c884574-4d81-4399-d022-c9a21c188c14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Can not perform a '--user' install. User site-packages are not visible in this virtualenv.\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform google-cloud-storage google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d620d1c",
      "metadata": {
        "id": "1d620d1c"
      },
      "source": [
        "\n",
        "```markdown\n",
        "Next, please fill in your Google Cloud project details and other configuration values below.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aa8092f",
      "metadata": {
        "id": "6aa8092f"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Your Google Cloud project ID\n",
        "PROJECT_ID = \"geminienterprise-485114\"\n",
        "# The region for your resources\n",
        "LOCATION = \"us-central1\"\n",
        "# Your Google Cloud Storage bucket name\n",
        "GCS_BUCKET = \"your-gcs-bucket-name\"\n",
        "# Your BigQuery dataset name\n",
        "# BIGQUERY_DATASET = \"your_bigquery_dataset\"\n",
        "\n",
        "# Authenticate with Google Cloud\n",
        "if \"google.colab\" in str(get_ipython()):\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9da5ecfd",
      "metadata": {
        "id": "9da5ecfd"
      },
      "source": [
        "```markdown\n",
        "## 2. Data Generation with Vertex AI\n",
        "\n",
        "Now, let's generate some multimodal data using different Vertex AI models.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f8d28fb",
      "metadata": {
        "id": "7f8d28fb"
      },
      "source": [
        "```markdown\n",
        "### 2.1 Generate an Image with Imagen\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ff521e6",
      "metadata": {
        "id": "1ff521e6"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "\n",
        "image_model = ImageGenerationModel.from_pretrained(\"imagegeneration@005\")\n",
        "\n",
        "image_prompt = \"a futuristic banana-shaped spaceship flying through a nebula\"\n",
        "response = image_model.generate_images(prompt=image_prompt)\n",
        "\n",
        "image = response.images[0]\n",
        "image.save(\"generated_image.png\")\n",
        "print(\"Image generated and saved as generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff21461c",
      "metadata": {
        "id": "ff21461c"
      },
      "source": [
        "```markdown\n",
        "### 2.2 Generate Music with Lyria\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d825725",
      "metadata": {
        "id": "4d825725"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import TextGenerationModel\n",
        "\n",
        "# Using a text model as a placeholder for Lyria access which is more complex\n",
        "# This simulates generating a prompt for a music model\n",
        "music_prompt = \"A short, upbeat, futuristic synthwave track for a space video game.\"\n",
        "\n",
        "# In a real scenario, you would use the appropriate Lyria model endpoint here.\n",
        "# For this notebook, we will save the prompt as a text file to represent the music generation.\n",
        "with open(\"generated_music_prompt.txt\", \"w\") as f:\n",
        "    f.write(music_prompt)\n",
        "\n",
        "print(\"Music prompt saved as generated_music_prompt.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0790ea5",
      "metadata": {
        "id": "a0790ea5"
      },
      "source": [
        "```markdown\n",
        "### 2.3 Generate Speech with Gemini TTS\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52bee2e",
      "metadata": {
        "id": "d52bee2e"
      },
      "outputs": [],
      "source": [
        "from google.cloud import texttospeech\n",
        "\n",
        "client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "synthesis_input = texttospeech.SynthesisInput(text=\"Hello, this is a test of the Gemini Text-to-Speech API.\")\n",
        "voice = texttospeech.VoiceSelectionParams(language_code=\"en-US\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL)\n",
        "audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n",
        "\n",
        "response = client.synthesize_speech(input=synthesis_input, voice=voice, audio_config=audio_config)\n",
        "\n",
        "with open(\"generated_speech.mp3\", \"wb\") as out:\n",
        "    out.write(response.audio_content)\n",
        "    print('Audio content written to file \"generated_speech.mp3\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da1f6e5a",
      "metadata": {
        "id": "da1f6e5a"
      },
      "source": [
        "```markdown\n",
        "## 3. Upload to Google Cloud Storage\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5bf9d1d",
      "metadata": {
        "id": "b5bf9d1d"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(GCS_BUCKET)\n",
        "\n",
        "def upload_to_gcs(filename):\n",
        "    blob = bucket.blob(filename)\n",
        "    blob.upload_from_filename(filename)\n",
        "    return f\"gs://{GCS_BUCKET}/{filename}\"\n",
        "\n",
        "image_gcs_uri = upload_to_gcs(\"generated_image.png\")\n",
        "music_gcs_uri = upload_to_gcs(\"generated_music_prompt.txt\")\n",
        "speech_gcs_uri = upload_to_gcs(\"generated_speech.mp3\")\n",
        "\n",
        "print(f\"Image URI: {image_gcs_uri}\")\n",
        "print(f\"Music URI: {music_gcs_uri}\")\n",
        "print(f\"Speech URI: {speech_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94c153e8",
      "metadata": {
        "id": "94c153e8"
      },
      "source": [
        "\n",
        "```markdown\n",
        "## 4. Create BigQuery Table\n",
        "\n",
        "Now we'll create a JSONL file with metadata about our generated assets and upload it to GCS. Then we'll create a BigQuery external table that points to this metadata file.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3591f259",
      "metadata": {
        "id": "3591f259"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "metadata = [\n",
        "    {\"prompt\": image_prompt, \"gcs_uri\": image_gcs_uri, \"type\": \"image\"},\n",
        "    {\"prompt\": music_prompt, \"gcs_uri\": music_gcs_uri, \"type\": \"music\"},\n",
        "    {\"prompt\": \"Hello, this is a test of the Gemini Text-to-Speech API.\", \"gcs_uri\": speech_gcs_uri, \"type\": \"speech\"}\n",
        "]\n",
        "\n",
        "with open(\"metadata.jsonl\", \"w\") as f:\n",
        "    for item in metadata:\n",
        "        f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "metadata_gcs_uri = upload_to_gcs(\"metadata.jsonl\")\n",
        "print(f\"Metadata GCS URI: {metadata_gcs_uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a54793",
      "metadata": {
        "id": "a0a54793"
      },
      "outputs": [],
      "source": [
        "from google.cloud import bigquery\n",
        "\n",
        "bq_client = bigquery.Client()\n",
        "\n",
        "dataset_id = f\"{PROJECT_ID}.{BIGQUERY_DATASET}\"\n",
        "try:\n",
        "    bq_client.get_dataset(dataset_id)  # Make an API request.\n",
        "    print(f\"Dataset {dataset_id} already exists.\")\n",
        "except Exception:\n",
        "    dataset = bigquery.Dataset(dataset_id)\n",
        "    dataset.location = LOCATION\n",
        "    dataset = bq_client.create_dataset(dataset, timeout=30)\n",
        "    print(f\"Created dataset {PROJECT_ID}.{dataset.dataset_id}\")\n",
        "\n",
        "table_id = f\"{dataset_id}.multimodal_assets\"\n",
        "schema = [\n",
        "    bigquery.SchemaField(\"prompt\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"gcs_uri\", \"STRING\"),\n",
        "    bigquery.SchemaField(\"type\", \"STRING\"),\n",
        "]\n",
        "\n",
        "external_config = bigquery.ExternalConfig(\"NEWLINE_DELIMITED_JSON\")\n",
        "external_config.source_uris = [metadata_gcs_uri]\n",
        "external_config.schema = schema\n",
        "table = bigquery.Table(table_id, schema=schema)\n",
        "table.external_data_configuration = external_config\n",
        "table = bq_client.create_table(table, exists_ok=True)\n",
        "\n",
        "print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d99e7f3",
      "metadata": {
        "id": "4d99e7f3"
      },
      "source": [
        "```markdown\n",
        "## 5. Analyze Data with BigQuery and Gemini\n",
        "\n",
        "Finally, we'll create a remote model in BigQuery that points to the Gemini Pro Vision model. This will allow us to analyze the images directly from BigQuery using SQL.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2b05e1",
      "metadata": {
        "id": "2b2b05e1"
      },
      "outputs": [],
      "source": [
        "# This step assumes you have a BigQuery connection to Vertex AI set up.\n",
        "# See: https://cloud.google.com/bigquery/docs/create-cloud-resource-connection\n",
        "CONNECTION_NAME = \"your-bq-connection-to-vertex-ai\"\n",
        "\n",
        "sql_create_model = f\"\"\"\n",
        "CREATE OR REPLACE MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`\n",
        "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_NAME}`\n",
        "OPTIONS (remote_service_type = 'CLOUD_AI_LARGE_LANGUAGE_MODEL_V1');\n",
        "\"\"\"\n",
        "\n",
        "query_job = bq_client.query(sql_create_model)\n",
        "query_job.result()  # Wait for the job to complete\n",
        "print(\"BigQuery remote model created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dc30d9b",
      "metadata": {
        "id": "6dc30d9b"
      },
      "outputs": [],
      "source": [
        "sql_analyze = f\"\"\"\n",
        "SELECT\n",
        "    prompt,\n",
        "    gcs_uri,\n",
        "    ml_generate_text_result['predictions'][0]['content'] AS gemini_analysis\n",
        "FROM\n",
        "    ML.GENERATE_TEXT(\n",
        "        MODEL `{PROJECT_ID}.{BIGQUERY_DATASET}.gemini_vision_model`,\n",
        "        (SELECT prompt, gcs_uri FROM `{table_id}` WHERE type = 'image'),\n",
        "        STRUCT('Analyze the following image:' AS prompt, TRUE AS flatten_json_output)\n",
        "    );\n",
        "\"\"\"\n",
        "\n",
        "df = bq_client.query(sql_analyze).to_dataframe()\n",
        "print(df.to_markdown())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}